{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability.python.distributions as tfp\n",
    "from collections import deque\n",
    "import random as rand\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import scipy.stats as spst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self, obssize, actsize, sess, optimizer):\n",
    "        \"\"\"\n",
    "        obssize: size of the states\n",
    "        actsize: size of the actions\n",
    "        \"\"\"\n",
    "        # BUILD PREDICTION GRAPH\n",
    "        # build the input\n",
    "        state = tf.placeholder(tf.float32, [None, obssize])\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        W1 = tf.Variable(initializer([obssize, 50]))\n",
    "        b1 = tf.Variable(initializer([50]))\n",
    "        W2 = tf.Variable(initializer([50, actsize]))\n",
    "        b2 = tf.Variable(initializer([actsize]))\n",
    "        \n",
    "        h1 = tf.nn.sigmoid(tf.matmul(state, W1) + b1)\n",
    "        h = tf.matmul(h1, W2) + b2\n",
    "        \n",
    "        prob = tf.nn.softmax(h, axis=1)  # prob is of shape [None, actsize], axis should be the one for each sample = axis = 1\n",
    "        probs_buffer = tf.placeholder(tf.float32, [5,None,actsize])\n",
    "        weights_ = tf.placeholder(tf.float32, [5])\n",
    "        weights = tf.nn.softmax(weights_)\n",
    "        \n",
    "        #########################   KL   ##########################\n",
    "\n",
    "        X = tfp.Categorical(probs=prob)\n",
    "        Y = tfp.Categorical(probs=probs_buffer)\n",
    "        distance = tfp.kl_divergence(X, Y)# a tensor containing the distances of distribution for each state and \n",
    "                                          # each policy from the replay buffer dim(5,len(OBS))\n",
    "        exploration_loss_KL_ = tf.reduce_mean(distance, axis=1)\n",
    "        exploration_loss_KL = tf.tensordot(exploration_loss_KL_, weights, axes=[0,0])\n",
    "        \n",
    "        #########################   L1   ###########################\n",
    "        Dif_ = probs_buffer - prob\n",
    "        norm_L1 = tf.norm(Dif_, axis=2,  ord=1)\n",
    "        exploration_loss_L1_ = tf.reduce_mean(norm_L1, axis=1)\n",
    "        exploration_loss_L1 = tf.tensordot(exploration_loss_L1_, weights, axes=[0,0])\n",
    "\n",
    "        #########################   L2   ###########################\n",
    "        norm_L2 = tf.norm(Dif_ + 1e-5, axis=2,  ord=2)\n",
    "        exploration_loss_L2_ = tf.reduce_mean(norm_L2, axis=1)\n",
    "        exploration_loss_L2 = tf.tensordot(exploration_loss_L2_, weights, axes=[0,0])\n",
    "        \n",
    "        ########################   Linf   ###########################\n",
    "        \n",
    "        norm_Linf = tf.norm(Dif_, axis=2,  ord=np.inf)\n",
    "        exploration_loss_Linf_ = tf.reduce_mean(norm_Linf, axis=1)\n",
    "        exploration_loss_Linf = tf.tensordot(exploration_loss_Linf_, weights, axes=[0,0])\n",
    "        \n",
    "        ########################   JS   ############################\n",
    "        \n",
    "        m = 0.5*(probs_buffer + prob)\n",
    "        M = tfp.Categorical(probs=m)\n",
    "        X = tfp.Categorical(probs=prob)\n",
    "        Y = tfp.Categorical(probs=probs_buffer)\n",
    "        JS = 0.5* tfp.kl_divergence(X, M) + tfp.kl_divergence(Y, M)\n",
    "        exploration_loss_JS_ = tf.reduce_mean(JS, axis=1)\n",
    "        exploration_loss_JS = tf.tensordot(exploration_loss_JS_, weights, axes=[0,0])\n",
    "        ############################################################\n",
    "        \n",
    "        Q_estimate = tf.placeholder(tf.float32, [None])\n",
    "        actions = tf.placeholder(tf.int32, [None])\n",
    "        actions_one_hot = tf.one_hot(actions, actsize) # actions_one_hot will be a matrix of shape(n,2)\n",
    "        action_probabilities = tf.reduce_sum(prob * actions_one_hot, axis=1) # this will connect the action that was \n",
    "                                                                             # actually played to to its probability\n",
    "        \n",
    "        \n",
    "        surrogate_loss = -tf.reduce_mean(tf.log(action_probabilities)*Q_estimate)\n",
    "        explore_alpha = tf.placeholder(tf.float32,[])\n",
    "        loss_and_exploration_loss_KL = surrogate_loss - explore_alpha*exploration_loss_KL\n",
    "        loss_and_exploration_loss_L1 = surrogate_loss - explore_alpha*exploration_loss_L1\n",
    "        loss_and_exploration_loss_L2 = surrogate_loss - explore_alpha*exploration_loss_L2\n",
    "        loss_and_exploration_loss_Linf = surrogate_loss - explore_alpha*exploration_loss_Linf\n",
    "        loss_and_exploration_loss_JS = surrogate_loss - explore_alpha*exploration_loss_JS\n",
    "        self.train_op = optimizer.minimize(surrogate_loss)\n",
    "        self.train_explore_KL = optimizer.minimize(loss_and_exploration_loss_KL)\n",
    "        self.train_explore_L1 = optimizer.minimize(loss_and_exploration_loss_L1)\n",
    "        self.train_explore_L2 = optimizer.minimize(loss_and_exploration_loss_L2)\n",
    "        self.train_explore_Linf = optimizer.minimize(loss_and_exploration_loss_Linf)\n",
    "        self.train_explore_JS = optimizer.minimize(loss_and_exploration_loss_JS)\n",
    "        \n",
    "        # some bookkeeping\n",
    "        self.state = state\n",
    "        self.prob = prob\n",
    "        self.actions = actions\n",
    "        self.Q_estimate = Q_estimate\n",
    "        self.loss = surrogate_loss\n",
    "        self.optimizer = optimizer\n",
    "        self.sess = sess\n",
    "        self.explore_alpha = explore_alpha\n",
    "        self.exploration_loss_KL = exploration_loss_KL\n",
    "        self.exploration_loss_L1 = exploration_loss_L1\n",
    "        self.exploration_loss_L2 = exploration_loss_L2\n",
    "        self.exploration_loss_Linf = exploration_loss_Linf\n",
    "        self.exploration_loss_JS = exploration_loss_JS\n",
    "        self.probs_buffer = probs_buffer\n",
    "        self.weights = weights\n",
    "    \n",
    "    def compute_prob(self, states):\n",
    "        \"\"\"\n",
    "        compute prob over actions given states pi(a|s)\n",
    "        states: numpy array of size [numsamples, obssize]\n",
    "        return: numpy array of size [numsamples, actsize]\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.prob, feed_dict={self.state:states})\n",
    "\n",
    "    def train(self, states, actions, Qs):\n",
    "        \"\"\"\n",
    "        states: numpy array (states)\n",
    "        actions: numpy array (actions)\n",
    "        Qs: numpy array (Q values)\n",
    "        \"\"\"\n",
    "        self.sess.run(self.train_op, feed_dict={self.state:states, self.actions:actions, self.Q_estimate:Qs})\n",
    "        \n",
    "    def train_expl(self, states, actions, Qs, probs, expl_alpha, weights, distance_metric):\n",
    "        \"\"\"\n",
    "        states: numpy array (states)\n",
    "        actions: numpy array (actions)\n",
    "        Qs: numpy array (Q values)\n",
    "        batch_Q: numpy array as input to compute loss_explore\n",
    "        exploration_alpha: numpy array as input to loss_and_exploration_loss\n",
    "        distance_metrix: string representing method to use for exploration\n",
    "        \n",
    "        \"\"\"\n",
    "        if distance_metric == \"KL\":\n",
    "            return self.sess.run(self.train_explore_KL, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.explore_alpha:expl_alpha, self.weights:weights})\n",
    "        elif distance_metric == \"L1\":\n",
    "            return self.sess.run(self.train_explore_L1, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.explore_alpha:expl_alpha, self.weights:weights})\n",
    "        elif distance_metric == \"L2\":\n",
    "            return self.sess.run(self.train_explore_L2, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.explore_alpha:expl_alpha, self.weights:weights})\n",
    "        \n",
    "        elif distance_metric == \"Linf\":\n",
    "            return self.sess.run(self.train_explore_Linf, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.explore_alpha:expl_alpha, self.weights:weights})\n",
    "        elif distance_metric == \"JS\":\n",
    "            return self.sess.run(self.train_explore_JS, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.explore_alpha:expl_alpha, self.weights:weights})\n",
    "    \n",
    "    \n",
    "    def compute_exploration_loss(self, states, actions, Qs, probs, weights, distance_metric):\n",
    "        \"\"\"\n",
    "        states: numpy array as input to compute loss (s)\n",
    "        actions: numpy array as input to compute loss (a)\n",
    "        targets: numpy array as input to compute loss (Q targets)\n",
    "        batch_Q: numpy array as input to compute loss_explore\n",
    "        distance_metric: string \n",
    "        \"\"\"\n",
    "        if distance_metric == \"KL\":\n",
    "            return self.sess.run(self.exploration_loss_KL, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.weights:weights})\n",
    "        elif distance_metric == \"L1\":\n",
    "            return self.sess.run(self.exploration_loss_L1, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.weights:weights})\n",
    "        elif distance_metric == \"L2\":\n",
    "            return self.sess.run(self.exploration_loss_L2, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.weights:weights})\n",
    "        elif distance_metric == \"Linf\":\n",
    "            return self.sess.run(self.exploration_loss_Linf, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.weights:weights})\n",
    "        elif distance_metric == \"JS\":\n",
    "            return self.sess.run(self.exploration_loss_JS, feed_dict={self.state:states, self.actions:actions,\\\n",
    "                                                            self.Q_estimate:Qs, self.probs_buffer:probs,\\\n",
    "                                                            self.weights:weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define value function as a class\n",
    "class ValueFunction(object):\n",
    "    def __init__(self, obssize, sess, optimizer):\n",
    "        \"\"\"\n",
    "        obssize: size of states\n",
    "        \"\"\"\n",
    "        state = tf.placeholder(tf.float32, [None, obssize])\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        W1 = tf.Variable(initializer([obssize, 50]))\n",
    "        b1 = tf.Variable(initializer([50]))\n",
    "        W2 = tf.Variable(initializer([50, 1]))\n",
    "        b2 = tf.Variable(initializer([1]))\n",
    "        \n",
    "        h1 = tf.nn.sigmoid(tf.matmul(state, W1) + b1) # dim = [num_of_samples, 30]\n",
    "        predictions = tf.matmul(h1, W2) + b2 # dim = [num_of_samples, 1]\n",
    "        \n",
    "        self.predictions = predictions\n",
    "        self.obssize = obssize\n",
    "        self.optimizer = optimizer\n",
    "        self.sess = sess\n",
    "        self.state = state\n",
    "        \n",
    "        \n",
    "        targets = tf.placeholder(tf.float32, [None])# first None because the number of sampled trajectories\n",
    "        # is not known beforehand and furthermore, the length of each trajectory might vary and is not constant. \n",
    "        # But in the end it is just a list of unkown size where each element is a number representing the value\n",
    "        # for the corresponding state in self.states\n",
    "        error = predictions - targets\n",
    "        loss = tf.reduce_mean(tf.square(error))\n",
    "        \n",
    "        self.targets = targets\n",
    "        self.train_op = optimizer.minimize(loss)\n",
    "\n",
    "    def compute_values(self, states):\n",
    "        \"\"\"\n",
    "        compute value function for given states\n",
    "        states: numpy array of size [numsamples, obssize]\n",
    "        return: numpy array of size [numsamples]\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.predictions, feed_dict={self.state:states})\n",
    "\n",
    "    def train(self, states, targets):\n",
    "        \"\"\"\n",
    "        states: numpy array\n",
    "        targets: numpy array\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.train_op, feed_dict={self.state:states, self.targets:targets}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_rewards(r, gamma):\n",
    "    \"\"\" \n",
    "    take 1D float array of rewards and compute discounted reward \n",
    "    returns a list where the first element is the complete discounted reward for the whole trajectory (already summed),\n",
    "    the second element is the complete discounted reward for the trajectory starting at t=1 and so on...\n",
    "    \"\"\"\n",
    "    \n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_sum = 0\n",
    "    for i in reversed(range(0,len(r))):\n",
    "        discounted_r[i] = running_sum * gamma + r[i]\n",
    "        running_sum = discounted_r[i]\n",
    "    return list(discounted_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_update(from_scope, to_scope):\n",
    "    \"\"\"\n",
    "    from_scope: string representing the scope of the network FROM which the variables will be copied\n",
    "    to_scope: string representing the scope of the network TO which the variables will be copied\n",
    "    \"\"\"\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=from_scope)\n",
    "    to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=to_scope)\n",
    "    op = []\n",
    "    for v1, v2 in zip(from_vars, to_vars):\n",
    "        op.append(v2.assign(v1))\n",
    "    return op    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement replay buffer\n",
    "import random\n",
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, maxlength):\n",
    "        \"\"\"\n",
    "        maxlength: max number of tuples to store in the buffer\n",
    "        if there are more tuples than maxlength, pop out the oldest tuples\n",
    "        \"\"\"\n",
    "        self.buffer = deque()\n",
    "        self.number = 0\n",
    "        self.maxlength = maxlength\n",
    "    \n",
    "    def append(self, experience):\n",
    "        \"\"\"\n",
    "        this function implements appending new experience tuple\n",
    "        experience: a tuple of the form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        self.buffer.append(experience)\n",
    "        self.number += 1\n",
    "        \n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        pop out the oldest tuples if self.number > self.maxlength\n",
    "        \"\"\"\n",
    "        while self.number > self.maxlength:\n",
    "            self.buffer.popleft()\n",
    "            self.number -= 1\n",
    "    \n",
    "    def sample(self, batchsize):\n",
    "        \"\"\"\n",
    "        this function samples 'batchsize' experience tuples\n",
    "        batchsize: size of the minibatch to be sampled\n",
    "        return: a list of tuples of form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        batch = random.sample(self.buffer, batchsize)\n",
    "            \n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd81eXZx/HPlR2yGBmEJBDCChA2IktFAQUXVkXRatVKHdWqVevo02r1sdo+jtZRtdRtrQvQgqKIKAIyw0gYYWQA2ZMMCJnnfv44h0gG5BBOcpJzrvfrxYszfjm5Tk7yzZ3rd5/7FmMMSimlXIuHswtQSinleBruSinlgjTclVLKBWm4K6WUC9JwV0opF6ThrpRSLkjDXSmlXJCGu1JKuSANd6WUckFezvrEoaGhJjY21lmfXimluqQtW7YUGWPCWjvOaeEeGxtLYmKisz69Ukp1SSJy0J7jtC2jlFIuSMNdKaVckIa7Ukq5IA13pZRyQRruSinlgloNdxHxE5FNIpIkIrtE5IkWjvEVkY9FJFVENopIbHsUq5RSyj72jNyrgQuMMaOA0cAsEZnY5JhbgcPGmIHA34C/OrZMpZRSp6PVcDdWR2xXvW3/mu7NNwd413Z5ITBdRMRhVSrVBWw5eJhthw47uwylADt77iLiKSLbgQJghTFmY5NDooBMAGNMHVAG9HJkoUp1Zmv2FzJvwXru/s82dF9i1RnYFe7GmHpjzGggGpggIglNDmlplN7sO1xEbhORRBFJLCwsPP1qleoEmob39sxSbn9/C96eHmSXHmNf/pGTfKRSHee0ZssYY0qBVcCsJndlATEAIuIFhAAlLXz8AmPMeGPM+LCwVpdGUMohdmSV8fSyFKrr6s/4sVam5DPuqW+57OW1vPLdfr7fW8Atb28iNNCXT26fBMC3Kfln/HmUOlP2zJYJE5Hutsv+wAxgT5PDlgA32S5fDXxn9G9T1Qn8sK+QaxesZ8HqdL7fc2Z/LX6ZnMvt728hPMgXTw/huW/2ccvbm/H08OD9WyeQEBXCiKgQVmq4q07AnoXDIoF3RcQT6y+DT4wxX4jIk0CiMWYJ8CbwvoikYh2xz2u3ipWy0+KtWTy0MJnBEUHklh3jq525zEro3abHWrgli4cWJjG2bw/euuUsgv28ySurYtXeAs7q35N+vQIAmD40nBdX7qf4SDW9An0d+XSUOi32zJZJNsaMMcaMNMYkGGOetN3+mC3YMcZUGWPmGmMGGmMmGGPS27twpU5l8dYs7v8kibPjevLx7RO5aHhvVqYUUFV7+q2ZjzYd4sFPk5g8IJT3bp1AsJ83AL1D/Jg3oS8DwgIbjp0eH4Ex8P3elv9KWL2vkGnPfs/yXXlte2JK2Unfoapc0oLV6SREBfP2zRMI8vNm9ohIjlTXsXZ/UaPjWusefpKYyaOf7eC8wWG8cdN4uvmc+o/dhKhgIoJ9+W5P49aMMYa31mZw89ubOFhSyaOLd1B0pLptT04pO2i4qy6t5GgN9ZbGAb0nr5w9eRVcMz4GHy/rt/jkAb0I8fdm2c7chuPKq2qZ/sIP/ObDbVTW1DV77MVbs3h4UTJTB4byzxvH4eft2Wo9IsIF8eGs3ldETZ0FgJo6C48u3sGTX+xm+tAIFt85mSNVdTz+311n8tSVOiUNd9VlrdlfyMRnVvLk0sYh+fm2HDw9hEtGRDbc5u3pwcxhEazYnd8Qus8t30tG0VG+SM7h6tfWk116DID88iqe/2YvD36axKS4Xiy4cbxdwX7c9PgIjlTXsSmjhPzyKuYtWM9HmzO56/wB/POGcYzp24N7Zwziyx25LNuR2/oDKtUGTtuJSakzsS61iPnvJmKM4T+bDvGrc+OI7tENi8WwZHs25w4KbXZC8+IRvVm4JYt1aUWE+Hvz/oaD3Dw5lnMHhXHPh9u4/OW1jI/twbcpBdRbDLMTevP8NaPw97E/2AGmDAzF18uDf65OY09eBUer63jl+jFcOrJPwzG3nxvH1zvz+OPnO5kY14ueAT4O+bqo5owxfL0zj5nDIvDydJ/xrPs8U+UyNqQX88t3NxPbK4DPfj0FQfjH92kAbD5QQk5ZFVeMiWr2cVMGhhLk68WSpBweXbyDiCA/HrhwCOfHh/PZXVPo3s2bjRkl3Dq1P6senMZrN4xrtcfeEn8fT6YMDGXN/iICfDz57NdTGgU7gJenB8/OHUl5VS3PfbO3bV8IZZf1acXc+cFWvtntXlNUdeSuOqWq2nrSCo8Q7OdNSDdvauos/LC3kO/2FPBtSj59e3bjg1+dTWigL9eeFcOHmw5x1/kD+Hx7Dt18PJk5LKLZY/p6eTJ9aDiLt2YD8M8bxxHoa/0RGBgeyLf3n4fFgKfHmS+LdNf5A+nXqxv3zRhMiL93i8fE9w7m6nExLNySxf0zBxOqUyfbxfasUgBScsu5+IRWnavTcFed0tPLUnhvffN9gMODfLlybDS/nTmoIQx/ff4APt6cyd9W7GfF7jwuGt77pCPu2SMi+Xx7DjOHRXDR8MZz3kUETwctdzeuXw/G9evR6nG3Tu3Ph5sO8f76g/x25mDHfHLVSHJmGQApuRVOrqRjabirTumHfYWM79eDa86KofxYLfUWw+QBoQzvE4xHk5F1ZIg/8ybENPwymDO6T0sPCcAF8eE8MHMw106Iadf67TUwPJAZQ8N5f8NB7pw24LRO3Cr77Mi2hvve/HInV9KxtOeuOp2sw5UcLK7kkpGRXDM+hvnnxHH7eQMYER3SLNiPu3PaAHw8PQgN9GHqwNCTPra3pwe/mT6I8CC/9ir/tM0/J46SozUs2prl7FJcTtGRarJLjxEa6ENmyTGOVDef8uqqNNxVp7M+rRiAyQNOHtJNRYb48+efJfD4ZcO73IyIs/v3ZGR0CG+uycBi0SWZHGlHlnXUfuXYaAD25rlPa6Zr/RQot7A+rZheAT4Mjghs/eATzB0fw2WjTt6S6axEhPnnxJFedJSVewqcXY5LSc4qQwSusoX7njz3ac1ouKtOxRjDurRiJg7ohTtt5nVxQm+iuvvz/Dd7OepGrYP2tiO7lAFhgQyOCCTQ14s9bnRSVcNddSoZRUfJK69i8gD32sjLy9ODp65IYH/BEe78YCu19RZnl+R0jmhRJWeVMTIqBBEhvndQs7bMsZp6u9b5b7rERVeg4a46lXVt6Le7ivPjw/nzFQms3lfIw4uS3Xq7vk82ZzL2qRVntLhaXlkVBRXVjIwOAWBI7yBS8sobvq7GGOb9awP3f5x0ysdJziol4fHlbDnYbP+hTk3DXXUq69OKiQzxI7ZXN2eX4hTzJvTlvhmDWLw1myeW7qa4lXDbmF5M1uHKDqquY9TVW3jpu/2UVtbyn42H2vw4ybY3L42I7g5AfGQwFVV15JZVAbA7t5ykzFJW7M4/6SwaYwxPL0vhWG09P5xkGefOSsNddRoWi2F9ejGT3Kzf3tS90wdxw8S+vLPuABOeXskNb2zkk82ZzVoDP+wr5Lp/beB/v9jtpEpPbndOOX9asqtNrZVlO/PIOnyMsCBf3t9wsGGht9O1I7sMTw9hWGQwAPG9g4CfTqoef6dyTb2F709yInvV3kI2pJfgIbAts7RNdTiLhrvqNPbmV1BytMYtWzInEhH+d04CX94zlTvOiyPrcCUPLUrmrg+2Nmw2klZ4hLv/sxWLgTX7ixyyP2xb7M+voKC8qtntnyRm8s66A+w5zamHxhgWrE4jLiyA/7tqJIUV1Xy5I6dNtSVnlTEoPLBh4bchtnBPya2grt7Cf7dnc+GwCMKCfPl6Z/PNU+othr98tYd+vbpx9bhoth8q7VJTVTXcldOUVdYy6++ruf5fG1i0Jath79FJbnYytSUiwvA+Ifzuoni+f3Aaj106jOW78/j5Gxs5WHyU+e8m4uPpwZNzhlNZU8+mjJP3g9elWVfQTMl17DRAi8Vw/RsbeXxJ83Xpj7dENmUUn9ZjrksrZmd2ObedE8d5g8OICwvg7R8P2HX+YcHqNOa8spbkrFKMMSRnlTb02wGC/byJ6u7P3rwKVu8vpOhIDVePi+bCYRF8v7f5Ll2LtmaxN7+C3100hAn9e1FRXUda4RG7n0tbdv1yJA135TRPLN3F/oIjZB6u5IFPk3jum33E9upGVHd/Z5fWqYgIv5zan39cP5Yd2WVc8PwPZB2u5PUbxzF3XAy+Xh5810JbwRjDa6vSuOGNjXybks81r6/nx9SiFj5D2+wrqKCwoprNBw43Ct/aegu7cqy/SDYdOL2TkK//kEZYkC9XjInCw0O4ZUp/krPK2HLwcKsf+0liFklZZVz56jqeWLqbw5W1jLT124+L7x3EnrxyFm3Npkc3b6YNCWdWQm8qa+pZc8IuXVW19fxtxT5GRYdwyYhIxvS1Ps62Q/a1Zr7bk8+wx77mpZX7nTba13BXTvHNrjwWb8vmrmkDWP278/n0jkncMLEv984Y5OzSOq2LR0Ty71vPJqaHP89cOZKzYnvi7+PJ5AG9+G5PQaOAraiq5fb3t/DXr/cwOyGSb+8/lz7d/bnprU0sdtAyB+tSraPyoiPVZJYca7h9X34F1XUWgvy82JTROPiPbze4P795u2Z3Tjlr9hdx8+TYhjV2rhobRbCfF2//eOCUtRSUV5FacIRfTxvAxSMieWed9fgTR+4A8ZFBpBceZcXufC4f1QcfLw8mxvUi2M+rUWvm2eV7yS2r4tGLhyIi9O8VQIi/N9syG/+SeWttBgu3NP96bj1YisXACyv2cfM7m1s9Md4eNNxVhys5WsPvP9vBsMhg7r5gECLCWbE9eeqKEfxsTLSzy+vUJvTvyarfnc/V4376Ol0QH87B4krSi4423Pb4kl2s3FPAHy4ZyivXj2FgeBCf3DGJs2J7cv8nSfzlqz1nPJd+XVox/rYQ3nLopxH68bf8X392X4qOVJNxQl1bD5Xy5Be7ufHNTeSf0Ks/VlPPn5bsIsDHkxvO7tdwezcfL66b0JevduayK6fslLUAzE6I5KXrxvDSdWO4bkJfhtpOph43pHcwdRZDTZ2Fq2xfQ29PD2YMi+DblHxqbb34N9dmcNOkfkyMs7YIPTyE0THdG43cyypr+cvXe3hnXUazejKKjxLbqxtP/2wEG9KLueSltRwsPtrsuPak4a463GP/3UnZsVqemzuqYY9T1Xbnx4cDNMz42Jldxmfbspl/Tn/mnxPXMPMoxN+bd385gesmxPD6D2nMW7ChYWvBppIyS3li6a6Tvnmnrt7CxvRiLh/Vh0BfL7Ye/Cn0krLKCPbzYq4tPE88H7A0KQcfLw/Kq2r51XuJHKupp6q2ntveT2TzwRL+/LMRhHRrvP79LVP6Exroy9zX17d44hPgx1Tr7lrD+ljD/PJRfXjmyhF4N1lnaKjtpOrA8EBGRP00qp81vDdlx2p5+8cMHl6UzITYnvzh0mGNPnZM3+7sza9omDb5+fZsauospBcebXZO4EDRUWJDA7j+7L4svnOybVOWfS3W3l70J0t1qJdX7ueL5FzuuWBQww+iOjPRPboxOCKwoTXz9LIUuvt78+tpA5sd6+PlwTNXjuSl68awN6+Ci19cw7q05n34Z75K4e0fD7Bid8thujOnnIrqOqYOCmV0TPdGPfEd2aWMjO7OgLBAegX4NIR7Xb2FL5JzmB4fzovzxrAju4wHP03irg+2smZ/EX+9cmSLO2j1DvFj6W+mMigiiDv+vYW/f7uvUR/7+JIVk+J6tbrRSv/QAGJ6+nPz5NhG023PHRyGv7cnTy/bQ3d/H/7x87HNfjGM6dsDYyDZNiXy482ZAFTW1JN3wl8hxhgyio4S2ysAgISoEH4xKZYvknNabEe1Fw131SGMMfxtxT6eX7GPK8dE8evzmweParvz48PZlFHCkqQc1qUVc+/0QSfdAQqsI9svfjOVXgE+PLwoudFc8l05ZWxIL0EEXl2V1uJMleO/ECbG9WJsvx7sySvnaHUdVbX17MmtYES09S3/E/r3ZKMt3NelFVN0pIY5o/swc1gEj8yK58sduazcU8BTVyRwzVknX2M/ItiPj2+byJVjo/j7t/t5fXVaw32HSirJLj3GlIGtz7Ly8vRgzUMXcMPEfo1u9/O27tLl4+nB6zeOIyyo+a5Yo2OsJ1W3HjrMzuwydueWc/EI64YvaQU/tVwKK6qprKmnf2hAw223nRtHN29PXly5v9UaHaXVcBeRGBH5XkRSRGSXiNzbwjHTRKRMRLbb/j3WPuWqrsgYw/Pf7OPFlfuZOy6aZ+eOcshWduon0+MjqLMYHlqYTP/QAK4/u1+rHxMbGsAfLxtGZskxPknMbLj97R8P4O/tycOz4knOKuPH1ObTGdelFjMkIoiwIF/G9euBxVhbOSm55dRZDKNsJzIn9O9JdukxskuPsSQphyBfL6YNsbaRbjs3jt9dNITn5o5qFrYt8fP25Pm5o7ggPpx//pBOeVUtQEN9k0+xjr89nr5yBF/fd05DiDcV4u/NwPBAth0q5ePNmfh6efDbGdbds9KLfpoiefwcQ+wJ4d4zwIebJsfy5Y5c9nXQ6N2ekXsd8IAxZigwEbhLRIa1cNwaY8xo278nHVql6tKWJufyyvepzDsrhr9eNVKDvR2M7dudEH9vqussPDwr3u5zGdMGhzG+Xw9e/m4/VbX1FFZUs2R7DlePi+aWKbGEB/ny2g+pjT6muq6ezQdKmGwbKR8Pwy0HDzfsenR8CuKE/j0BWLu/kOU787gooXfDTBgR4a7zBzY6OdwaEeG3MwZTdqyWd20zaH5MKyIi2Je4E8K0LYL9vIkLO/Uy02NiurPl0GE+357N7ITeDAy3rjaZVvBTuB+wnTjt36txPb86J44AHy9e/LZjRu+tfgcYY3KNMVttlyuAFKB5Y0ypk1iyPYc+IX48/bMRJ91JSZ0ZL08P5o6LZsbQcC4a3nxz8JMRER64cAj55dX8e8NBPth4kJp6C7dMicXXy5P55/Tnx9Rikk546/22Q6VU11ka3kkc4u/N4IhAth46TFJmGaGBPkSGWHe6iu8dTJCfNdAqqutOuQWivUZEhzBjaDhvrM2g7FgtG9KKmTIgtEOWrBjTtwellbVUVNVxzfgYRIS4sIBGM5Uyiirx9hT6dG+821ePAB9uto3eO2LTkNPquYtILDAG2NjC3ZNEJElEvhKR4Q6oTbmAYzX1rE0t5MLhvTXY29kfLh3GGzedddohN2lAL6YODOXVVWn8e8NBLogPbxjBXn92P4L9vHht1U897nWpRXjIT6NysG4IvvVQKUlZ1pOpx2vw9LBOc80pqyI00IdJcY559/G9062j998v3kHx0ZozbsnY6/ibmWJ6+jdMkxwQFth45F50lJie3VrcEWz+Of0J8vXi/Q0H2r1Wu8NdRAKBRcB9xpim72PeCvQzxowCXgY+P8lj3CYiiSKSWFjYtVZYU22zZn8hVbUWZg6zfzSpOt4DFw6m5GgNRUdq+OWU/g23B/p6cdPkWJbvzuOeD7exeGsWq/YVMiIqpNEJ2zF9e1B2rJbUgiONphjCT78ELh3Zx2FbIB4fvX+5IxfArpOpjjA4Ioi40ADmT41rGKwMCAsgp6yKyhrrFMkDxUebtWSO697Nhw9vm8jjl7X/+Neur7SIeGMN9g+MMYub3m+MKTfGHLFdXgZ4i0izX6XGmAXGmPHGmPFhYWFnWLrqClbszifYz6vRKE91PmP69uCSEZGMjA5pFpS/OjeOueOi+TG1iPs/SSI5q4xJTRZ3G9evR8PlUTGNw316fDjdu3lzzfiTz4Zpi3unW09mxoUGEBnSMUtWeHoI3z04jZsmxzbcdvyvnPTCo1gshgPFRxudTG0qISqk2TTL9uDV2gFi/fvqTSDFGPPCSY7pDeQbY4yITMD6S+P0VgxSLqfeYli5p4AL4sM75JtZnZmXrhuDxZhmbZ1gP2/+7+pRWCyGnTllJB44zKWjIhsdExcaQPdu3pRW1jIiqvFsk0ERQWx/7EKH1zsiOoTbz4ujb0/nrv0/wBbuaYVH6BngQ1Wt5ZTh3lFaDXdgCnAjsENEtttu+z3QF8AY8zpwNXCniNQBx4B5xp23kVGAdfZEydEaZg7r7exSlB08PQRPTt6v9/AQRkZ3b7YYF1hPzI7v15M9eeUtzhFvL4/OHtphn+tk+vXqhoh15B4WaH3uJ2vLdKRWw90YsxZO8Ypbj3kFeMVRRSnXsGJ3Hj6eHpw3RFtw7uDPP0ugosr9Nvf28/Ykpkc30gqPEB5sDffYUOfvJGbPyF2p02aM4Zvd+Uwa0ItAX/02cwcRwX5EuOmKEgPCAkgvPEpkiB8+Xh706aBzAKeijVDVLvYXHOFgcSUXnsaca6W6qriwQNKLjpBeaF0NsjNM+9VwV+3i+BrXM4ZquCvXNyAskKpaC5sOlDQsGOZs+veyciiLxfDMVyn8a00Gl43qQ0SwX+sfpFQXNyDMGugVVXWNFgxzJg135TDHauq57+NtLN+Vz02T+vHHS1tagkgp13PimjSdYRokaLgrBzHGMP+9zaxLK+bxy4ZxywnvclTK1YUG+hDs50V5VV2nactoz105xNLkXH5MLeaJy4drsCu3Y11AzDp67yxtGQ13dcaO1dTzl2UpDIsM5ud2rCOulCsaFB5IgI8nEcEd9yauU9G2jDpj/1ydRk5ZFX+7drSu1a7c1r0zBvGzsVEdsvSwPTTc1RnJKT3G6z+kccmISM520HKuSnVF0T26Ed3D+e9MPU7bMuqM/OWrPRgDj8yOd3YpSqkTaLirNjtUXMmSpBxundqfGCevzKeUakzDXbXZwq1ZiGDX5sZKqY6l4a7axGIxLNqSxdSBofTp7vxFkpRSjWm4qzbZkF5Mdumx09q5XinVcTTcVZss3JJFkJ8XFw3XjTiU6ow03NVpq6iqZdnOXC4b1Qc/b09nl6OUaoGGuzpty3bkUlVr0ZaMUp2Yhrs6bQu3ZBEXFsCYmOZ7aSqlOgcNd3VaVqbks/nAYeaOi+k0b7NWSjWnyw8ouxhjeHVVGs99s5dhkcFcNyHG2SUppU5Bw121qqq2ngc/TeKLZOtJ1P+7aiT+PnoiVanOTMNdteqtHzP4IjmXR2bHc/u5cdqOUaoL0HBXrfpqRx6jY7pzx3kDnF2KUspOrZ5QFZEYEfleRFJEZJeI3NvCMSIiL4lIqogki8jY9ilXdbTs0mPsyC7TNysp1cXYM3KvAx4wxmwVkSBgi4isMMbsPuGY2cAg27+zgdds/6subvnOPAAuGh7h5EqUUqej1ZG7MSbXGLPVdrkCSAGimhw2B3jPWG0AuotIpMOrVR1u+a48BkcENtrdXSnV+Z3WPHcRiQXGABub3BUFZJ5wPYvmvwBUF1N8pJrNB0q0JaNUF2R3uItIILAIuM8YU9707hY+xLTwGLeJSKKIJBYWFp5eparDrUwpwGLQcFeqC7Ir3EXEG2uwf2CMWdzCIVnAie9qiQZymh5kjFlgjBlvjBkfFhbWlnpVB/p6Vx5R3f0Z3ifY2aUopU6TPbNlBHgTSDHGvHCSw5YAv7DNmpkIlBljch1Yp+pgR6rrWLu/iFkJvXVeu1JdkD2zZaYANwI7RGS77bbfA30BjDGvA8uAi4FUoBK4xfGlqo60am8BNfUWbcko1UW1Gu7GmLW03FM/8RgD3OWoopTzGGP47/YcnvoyhfAgX8b16+HskpRSbaDvUFUNMoqO8j+f7WBdWjGjokN45sqReHpoS0aprkjDXQHWEfvNb2+i5GgN/3tFAtdP6KvBrlQXpuGuANiWWcrB4kqemztKd1hSygXoZh0KgKVJOfh4eXChLjOglEvQcFfUWwxfJOdy/pAwgv28nV2OUsoBNNwVGzOKKayo5rJRfZxdilLKQTTcFUuTcunm48n0eG3JKOUqNNzdXG29ha925jJzWIRunaeUC9Fwd3NrU4sorazlspHaklHKlWi4u7ml23MI9vPinMGhzi5FKeVAGu5uLLOkkuW78piV0BtfL23JKOVKNNzdVGFFNTe+uREvTw9u142vlXI5Gu5uqKKqlpvf3kR+eTVv3XwWA3QLPaVcjoa7m6muq+e297awN6+CV28Yq6s+KuWidG0ZN/PKd6msTy/mb9eO4vwh4c4uRynVTnTk7kZ25ZTx6qo0rhwbxc/G6OJgSrkyDXc3UVtv4aGFyfTo5sNjlw5zdjlKqXambRk3sWB1Ortyynn9hrF07+bj7HKUUu1MR+5uILXgCC9+u59LRkQyKyHS2eUopTqAhrsbeGddBh4e8KfLhzu7FKVUB9Fwd3F19RaW7chjxtAIwoJ8nV2OUqqDaLi7uHVpxZQcrdG12pVyMxruLm5JUg5Bfl5MGxLm7FKUUh1Iw92FVdfVs3xnHhcN14XBlHI3rYa7iLwlIgUisvMk908TkTIR2W7795jjy1Rt8cPeQiqq67Qlo5Qbsmee+zvAK8B7pzhmjTHmUodUpBxmaXIuPQN8mDygl7NLUUp1sFZH7saY1UBJB9SiHKiypo5vd+czO6E33p7afVPK3Tjqp36SiCSJyFcictLJ1CJym4gkikhiYWGhgz61asnKlAKO1dZrS0YpN+WIcN8K9DPGjAJeBj4/2YHGmAXGmPHGmPFhYTp7oz19tPkQEcG+nBXb09mlKKWc4IzD3RhTbow5Yru8DPAWEd2Q04k2phfzY2oxvzonDk8PcXY5SiknOONwF5HeIiK2yxNsj1l8po+r2sYYwwsr9hEW5MsNE/s5uxyllJO0OltGRD4EpgGhIpIFPA54AxhjXgeuBu4UkTrgGDDPGGParWJ1SuvTitmYUcKfLhuGn7fObVfKXbUa7saY61q5/xWsUyWVkxljeH7FPiJD/Jg3oa+zy1FKOZHOkXMhq/cXseXgYe46f6CO2pVycxruLqKmzsJfv9pDVHd/rhkf4+xylFJOpuHuIv7y1R5255bzx0uH4uOlL6tS7k5TwAUs35XHWz9mcPPkWN1pSSkFaLh3eZkllfzu0yRGRIXw6MXxzi5HKdVJaLh3YfUWw90fbsMY+Mf1Y3VZX6VUA3tWhVSd1De78kjKLOWFa0bRt1c3Z5ejlOpEdOTeRRljeH11On17dmPO6Chnl6MHr5z6AAAOT0lEQVSU6mQ03LuoTRklJGWW8qtzdf0YpVRzGu5d1D9Xp9MrwIe546KdXYpSqhPScO+C9uVX8N2eAn4xKVbfiaqUapGGexe0YHU6/t6e/GKSrvqolGqZhnsXk116jP9uz+bas2LoEeDj7HKUUp2UhnsXYozh0cU78PLwYP45/Z1djlKqE9Nw70L+s+kQq/cV8vuL44nuofPalVInp+HeRRwqruTPX6YwdWAoPz9be+1KqVPTcO8CLBbDg58m4SnC/109Eg+d166UaoWGexfw0eZMNh0o4fHLh9Onu7+zy1FKdQEa7p2cxWL415p0RsV056qxusyAUso+Gu6d3Kp9BWQUHeXWqf0R0XaMUso+Gu6d3FtrD9A72I/ZCb2dXYpSqgvRcO/E9uZVsDa1iF9M7oe3p75USin7aWJ0Ym+tzcDP24Przurr7FKUUl2MhnsnVXykms+2Z3Pl2GhdZkApddpaDXcReUtECkRk50nuFxF5SURSRSRZRMY6vkz38+baDGrqLPxySqyzS1FKdUH2jNzfAWad4v7ZwCDbv9uA1868LPf29o8ZvLoqjTmj+zAwPMjZ5SiluqBWw90YsxooOcUhc4D3jNUGoLuIRDqqQHfzxpp0nli6m4uGR/Ds1aOcXY5SqotyRM89Csg84XqW7bZmROQ2EUkUkcTCwkIHfGrX8q/V6Tz1ZQqXjIjklevH4uOlp0SUUm3jiPRo6Z01pqUDjTELjDHjjTHjw8LCHPCpXUdSZinPfJXCxSN68+K80Tr1USl1RhyRIFlAzAnXo4EcBzyu26itt/DwomTCgnz5y1Uj8dJgV0qdIUekyBLgF7ZZMxOBMmNMrgMe1238a006e/IqeHJOAsF+3s4uRynlArxaO0BEPgSmAaEikgU8DngDGGNeB5YBFwOpQCVwS3sV64oyio7y92/3M2t4by4arksMKKUco9VwN8Zc18r9BrjLYRW5kXqL4dHFyfh6efDEnOHOLkcp5UK0ueskFovhdwuT2JBewh8uGUpEsJ+zS1JKuRANdyewWAy//2wHi7dmc//MwVyra8copRxMw72DGWN4bMlOPtqcyW8uGMg90wc5uySllAvScO9g/95wkH9vOMTt58Vx/8zBzi5HKeWiNNw7UGZJJc98tYdzBoXyyKx43VlJKdVuNNw7iDHWPrsAz1w5QoNdKdWuNNw7yKdbslizv4hHZscT3aObs8tRSrk4DfcOkF9exf9+sZsJ/Xvy87P7ObscpZQb0HBvZ8YYHl6UTE2dhb9eNRIPD23HKKXan4Z7O/v3hoOs2lvI/1wylP6hAc4uRynlJjTc21FqwRGe+jKF8waHceNEbccopTqOhns7qamzcN/H2+jm48mzV4/U2TFKqQ7V6sJhqm1eWrmfndnlvH7DOMJ13RilVAfTkXs72HboMK+uSuXqcdHMStBlfJVSHU/D3cGO1dTzwCdJRIb48/hlw5xdjlLKTWlbxsGeXb6X9KKjfDD/bIJ0VyWllJPoyN2B1qcV89aPGdw0qR9TBoY6uxyllBvTcHeQvLIq7v9kO/1DA3hk9lBnl6OUcnMa7g5QdqyWm97aRPmxWl6+bgz+Pp7OLkkp5ea0536Gqmrr+dV7iaQXHeHtmyeQEBXi7JKUUkrD/UxYLIbffrydTRklvDhvNFMHaZ9dKdU5aFvmDCxYk85XO/P4n4uHMmd0lLPLUUqpBhrubbTlYAnPLt/LJSMimX9Of2eXo5RSjdgV7iIyS0T2ikiqiDzSwv03i0ihiGy3/Zvv+FI7j9LKGu75cDt9uvvxzFW6q5JSqvNptecuIp7AP4CZQBawWUSWGGN2Nzn0Y2PM3e1QY6dijOF3C5MpqKhi4R2TCdY3KimlOiF7Ru4TgFRjTLoxpgb4CJjTvmV1Xm+syWDF7nwemT2UUTHdnV2OUkq1yJ5wjwIyT7ieZbutqatEJFlEFopIjEOq62TWpRbxzFcpzE7ozS+nxDq7HKWUOil7wr2lhrJpcn0pEGuMGQl8C7zb4gOJ3CYiiSKSWFhYeHqVOllO6THu/nAbcWGBPDt3lPbZlVKdmj3hngWcOBKPBnJOPMAYU2yMqbZd/RcwrqUHMsYsMMaMN8aMDwsLa0u9TlFVW8+d/95CTZ2Ff944jkBffXuAUqpzsyfcNwODRKS/iPgA84AlJx4gIpEnXL0cSHFcic5VbzE8+GkSSVllPH/NKAaEBTq7JKWUalWrQ1BjTJ2I3A0sBzyBt4wxu0TkSSDRGLMEuEdELgfqgBLg5nasucNYLIZHFyfzRXIuj86O56LhuvGGUqprEGOats87xvjx401iYqJTPrc9jDE8sXQ376w7wD0XDOT+C4c4uySllEJEthhjxrd2nDaPW1BXb+HpZXt4Z90Bbp3an9/OHOzskpRS6rRouDdRUFHFPR9uY0N6CTdPjuUPlwzVmTFKqS5Hw/0EiQdK+PUHWymvquWFa0Zx5dhoZ5eklFJtouFusyOrjBve3EjvYD/e/eUEhkYGO7skpZRqMw13IL+8ivnvbaZXgC+f3jGZsCBfZ5eklFJnxO3Dvaq2ntveS6Siqo5Fd2qwK6Vcg1uHu8ViXeExObuMBTeO11aMUspluO1mHcYYHl+yi6VJOTx0UTwzh0U4uySllHIYtwx3YwxPfZnC+xsOcvu5cdxxXpyzS1JKKYdyu3A3xvDs8r28uTaDmyfH8sjseJ3HrpRyOW4X7m+uzeDVVWlcf3ZfHr9smAa7UsoluVW4f7s7nz8vs2628dScBA12pZTLcptw351Tzj0fbSOhTwgvXDMaDw8NdqWU63KLcC+oqGL+u5sJ9vPmjZvG4+/j6eySlFKqXbn8PPfyqlpufmszhytr+fSOSUQE+zm7JKWUancuPXKvqq1n/ruJ7Muv4LUbxpIQFeLskpRSqkO47Mi9rt7C3f/ZxuYDJfz92tFMGxLu7JKUUqrDuOTIvd5ieGhhMt+m5PPk5cOZMzrK2SUppVSHcrlwPx7si7dl88DMwdw4KdbZJSmlVIdzqXC3WAyPLEpm0dYsfjtjML+ZPsjZJSmllFO4TLhbLIZHF+/g0y1Z3Dt9EPfO0GBXSrkvlwh3i8XwP5/v4OPETO65YKBuaK2UcntdPtyNMfzxvzv5cFMmd50/QINdKaXo4uF+fE32DzYe4o7zBvDghUN0vRillMLOcBeRWSKyV0RSReSRFu73FZGPbfdvFJFYRxfakhdW7OO99Qe57dw4Hp6lwa6UUse1Gu4i4gn8A5gNDAOuE5FhTQ67FThsjBkI/A34q6MLber99Qd4+btU5p0Vw6O6JrtSSjViz8h9ApBqjEk3xtQAHwFzmhwzB3jXdnkhMF3aMW2X7cjlsSW7mDE0gqeu0KV7lVKqKXvCPQrIPOF6lu22Fo8xxtQBZUAvRxTY1Pq0Yu77aDtj+/bg5evG4OXZpU8bKKVUu7AnGVsaFps2HIOI3CYiiSKSWFhYaE99zfQM8OHsuJ68qUv3KqXUSdkT7llAzAnXo4Gckx0jIl5ACFDS9IGMMQuMMeONMePDwsLaVPCQ3kG8f+vZdO/m06aPV0opd2BPuG8GBolIfxHxAeYBS5ocswS4yXb5auA7Y0yzkbtSSqmO0eqSv8aYOhG5G1gOeAJvGWN2iciTQKIxZgnwJvC+iKRiHbHPa8+ilVJKnZpd67kbY5YBy5rc9tgJl6uAuY4tTSmlVFvpVBOllHJBGu5KKeWCNNyVUsoFabgrpZQL0nBXSikXJM6aji4ihcDBNn54KFDkwHK6Gnd//qBfA33+7vv8+xljWn0XqNPC/UyISKIxZryz63AWd3/+oF8Dff7u/fztoW0ZpZRyQRruSinlgrpquC9wdgFO5u7PH/RroM9fnVKX7LkrpZQ6ta46cldKKXUKXS7cW9us29WISIyIfC8iKSKyS0Tutd3eU0RWiMh+2/89nF1rexIRTxHZJiJf2K73t23Gvt+2ObvLLvAvIt1FZKGI7LF9H0xyp9dfRH5r+97fKSIfioifO73+bdWlwt3OzbpdTR3wgDFmKDARuMv2nB8BVhpjBgErbddd2b1AygnX/wr8zfb8D2PdpN1VvQh8bYyJB0Zh/Tq4xesvIlHAPcB4Y0wC1mXH5+Fer3+bdKlwx77Nul2KMSbXGLPVdrkC6w92FI03JX8XuMI5FbY/EYkGLgHesF0X4AKsm7GDCz9/EQkGzsW6ZwLGmBpjTClu9PpjXZrc37bLWzcgFzd5/c9EVwt3ezbrdlkiEguMATYCEcaYXLD+AgDCnVdZu/s78BBgsV3vBZTaNmMH1/4+iAMKgbdtbak3RCQAN3n9jTHZwHPAIayhXgZswX1e/zbrauFu10bcrkhEAoFFwH3GmHJn19NRRORSoMAYs+XEm1s41FW/D7yAscBrxpgxwFFctAXTEtu5hDlAf6APEIC1LduUq77+bdbVwt2ezbpdjoh4Yw32D4wxi20354tIpO3+SKDAWfW1synA5SJyAGsb7gKsI/nutj/TwbW/D7KALGPMRtv1hVjD3l1e/xlAhjGm0BhTCywGJuM+r3+bdbVwt2ezbpdi6y+/CaQYY1444a4TNyW/CfhvR9fWEYwxjxpjoo0xsVhf7++MMT8Hvse6GTu49vPPAzJFZIjtpunAbtzk9cfajpkoIt1sPwvHn79bvP5nosu9iUlELsY6cju+WfefnVxSuxKRqcAaYAc/9Zx/j7Xv/gnQF+sPwFxjTIlTiuwgIjINeNAYc6mIxGEdyfcEtgE3GGOqnVlfexGR0VhPJvsA6cAtWAdmbvH6i8gTwLVYZ45tA+Zj7bG7xevfVl0u3JVSSrWuq7VllFJK2UHDXSmlXJCGu1JKuSANd6WUckEa7kop5YI03JVSygVpuCullAvScFdKKRf0/3tM6XO6gDBRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune/add hyper-parameters numtrajs too high ? code is very slow\n",
    "# parameter initializations\n",
    "alpha = 1e-3  # learning rate for PG\n",
    "beta = 1e-3  # learning rate for baseline\n",
    "numtrajs = 15  # num of trajecories to collect at each iteration \n",
    "envname = \"CartPole-v0\"  # environment name\n",
    "gamma = .99  # discount\n",
    "episodes = 100 # total num of iterations\n",
    "maxlength = 5\n",
    "start = False\n",
    "exploration_alpha = 0.1\n",
    "distance_metric = \"L2\" # Options are: Linf, L1, L2, KL (for Kullback–Leibler divergence), JS (for Jensen–Shannon divergence)\n",
    "distribution_buffer = \"Unif\" # Options are: Unif, exp_high_recent, exp_high_old, reward_high\n",
    "# initialize environment\n",
    "env = gym.make(envname)\n",
    "obssize = env.observation_space.low.size\n",
    "actsize = env.action_space.n\n",
    "\n",
    "################# DO NOT CHANGE THIS PART ###################\n",
    "#wrapper for accounting rewards\n",
    "rEpisode=0\n",
    "rList=[]\n",
    "\n",
    "def reset_decorate(func):\n",
    "    def func_wrapper():\n",
    "        global rList\n",
    "        global rEpisode\n",
    "        rList.append(rEpisode)\n",
    "        rEpisode=0\n",
    "        return(func())\n",
    "    return func_wrapper\n",
    "\n",
    "env.reset = reset_decorate(env.reset)\n",
    "\n",
    "def step_decorate(func):\n",
    "    def func_wrapper(action):\n",
    "        global rEpisode\n",
    "        s1, r, d, other = func(action)\n",
    "        rEpisode+=r\n",
    "        return(s1, r, d, other)\n",
    "    return func_wrapper\n",
    "\n",
    "env.step = step_decorate(env.step)\n",
    "\n",
    "def init():\n",
    "    rEpisode=0\n",
    "    rList=[]\n",
    "    return;\n",
    "#########################################################\n",
    "\n",
    "# sess\n",
    "sess = tf.Session()\n",
    "\n",
    "# optimizer\n",
    "optimizer_p = tf.train.AdamOptimizer(alpha)\n",
    "optimizer_v = tf.train.AdamOptimizer(beta)\n",
    "\n",
    "# initialize networks\n",
    "with tf.variable_scope(\"actor\"):\n",
    "    actor = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "    \n",
    "baseline = ValueFunction(obssize, sess, optimizer_v)  # baseline initialization\n",
    "\n",
    "with tf.variable_scope(\"buffer_1\"):\n",
    "    buffer_1 = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "with tf.variable_scope(\"buffer_2\"):\n",
    "    buffer_2 = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "with tf.variable_scope(\"buffer_3\"):\n",
    "    buffer_3 = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "with tf.variable_scope(\"buffer_4\"):\n",
    "    buffer_4 = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "with tf.variable_scope(\"buffer_5\"):\n",
    "    buffer_5 = Policy(obssize, actsize, sess, optimizer_p)  # policy initialization\n",
    "    \n",
    "update1 = build_target_update(\"actor\", \"buffer_1\")\n",
    "update2 = build_target_update(\"actor\", \"buffer_2\")\n",
    "update3 = build_target_update(\"actor\", \"buffer_3\")\n",
    "update4 = build_target_update(\"actor\", \"buffer_4\")\n",
    "update5 = build_target_update(\"actor\", \"buffer_5\")\n",
    "\n",
    "# initialize tensorflow graphs\n",
    "sess.run(tf.global_variables_initializer())\n",
    "buffer = ReplayBuffer(maxlength)\n",
    "buffer_count = 1\n",
    "\n",
    "#logging info\n",
    "exploration_loss_log = np.array([])\n",
    "exploration_alpha_log = np.array([])\n",
    "avg_reward_per_policy = []\n",
    "reward_buffer_1, reward_buffer_2, reward_buffer_3, reward_buffer_4, reward_buffer_5 = 0,0,0,0,0\n",
    "# main iteration\n",
    "for ite in range(episodes):    \n",
    "\n",
    "    # trajs records for batch update\n",
    "    OBS = []  # observations\n",
    "    ACTS = []  # actions\n",
    "    ADS = []  # advantages (to update policy)\n",
    "    VAL = []  # value functions (to update baseline)\n",
    "\n",
    "    for num in range(numtrajs):\n",
    "        # record for each episode\n",
    "        obss = []  # observations\n",
    "        acts = []   # actions\n",
    "        rews = []  # instant rewards\n",
    "\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            prob = actor.compute_prob(np.expand_dims(obs,0))\n",
    "            action = np.random.choice(actsize, p=prob.flatten(), size=1)\n",
    "            newobs, reward, done, _ = env.step(action[0])\n",
    "\n",
    "            # record\n",
    "            obss.append(obs)\n",
    "            acts.append(action[0])\n",
    "            rews.append(reward)\n",
    "            #print(reward)\n",
    "\n",
    "            # update\n",
    "            obs = newobs\n",
    "\n",
    "        # compute returns from instant rewards for one whole trajectory\n",
    "        returns = discounted_rewards(rews, gamma)\n",
    "        avg_reward_per_policy += [sum(returns)]\n",
    "    \n",
    "        # record for batch update\n",
    "        VAL += returns # NOTE that the list of returns just gets extended. \n",
    "                       # There is no separate entry created for each trajectory\n",
    "        OBS += obss\n",
    "        ACTS += acts         \n",
    "    \n",
    "    # update baseline\n",
    "    VAL = np.array(VAL)# represents an array where the discounted reward lists are concatenated to each other.\n",
    "    # the size of VAL should be [numtrajs * len_of_traj_i, 1] where len_of_traj_i is variable depending on the length \n",
    "    # of each trajectory.\n",
    "    OBS = np.array(OBS)# represents an array where the list of states for all trajectories are concatenated.\n",
    "    # the size of OBS should be [numtrajs * len_of_traj_i, obssize]\n",
    "    ACTS = np.array(ACTS)\n",
    "    \n",
    "    baseline.train(OBS, VAL)  # update only one step\n",
    "    \n",
    "    # update policy\n",
    "    BAS = baseline.compute_values(OBS)  # compute baseline for variance reduction\n",
    "    ADS = VAL - np.squeeze(BAS,1) # computes advantages. An array of (targets)-(estimated from our network) for each\n",
    "                                  # state\n",
    "     \n",
    "    if buffer_count==1 :\n",
    "        sess.run(update1)\n",
    "        buffer_count += 1\n",
    "        reward_buffer_1 = sum(avg_reward_per_policy)\n",
    "    elif buffer_count==2 :\n",
    "        sess.run(update2)\n",
    "        buffer_count += 1\n",
    "        reward_buffer_2 = sum(avg_reward_per_policy)\n",
    "    elif buffer_count==3 :\n",
    "        sess.run(update3)\n",
    "        buffer_count += 1\n",
    "        reward_buffer_3 = sum(avg_reward_per_policy)\n",
    "    elif buffer_count==4 :\n",
    "        sess.run(update4)\n",
    "        buffer_count += 1\n",
    "        reward_buffer_4 = sum(avg_reward_per_policy)\n",
    "    elif buffer_count==5 :\n",
    "        sess.run(update5)\n",
    "        start = True\n",
    "        buffer_count = 0\n",
    "        reward_buffer_5 = sum(avg_reward_per_policy)\n",
    "        \n",
    "    if distribution_buffer == \"Unif\":\n",
    "        weights = np.array([1,1,1,1,1])\n",
    "    elif distribution_buffer == \"exp_high_recent\": # recent experience has a bigger historic order value\n",
    "            weights = np.roll(np.array([1,2,3,4,5]), buffer_count)\n",
    "    elif distribution_buffer == \"exp_high_older\": # older experience has a bigger historic order value                      \n",
    "            weights = np.roll(np.array([5,4,3,2,1]), buffer_count)\n",
    "    elif distribution_buffer == \"reward_high\": # experience with high reward has a bigger historic order value                      \n",
    "            weights = np.array([reward_buffer_1, reward_buffer_2, reward_buffer_3, reward_buffer_4, reward_buffer_5])\n",
    "    avg_reward_per_policy = []\n",
    "            \n",
    "    if start:    \n",
    "        prob1 = buffer_1.compute_prob(OBS)\n",
    "        prob2 = buffer_2.compute_prob(OBS)\n",
    "        prob3 = buffer_3.compute_prob(OBS)\n",
    "        prob4 = buffer_4.compute_prob(OBS)\n",
    "        prob5 = buffer_5.compute_prob(OBS)\n",
    "        probs_buffer = [prob1, prob2, prob3, prob4, prob5] # a tensor of dimension(5,len(OBS), 2)\n",
    "        \n",
    "        exploration_loss_log = np.append(exploration_loss_log, actor.compute_exploration_loss(\n",
    "                OBS, ACTS, ADS, probs_buffer, weights, distance_metric))\n",
    "        exploration_alpha_log = np.append(exploration_alpha_log, exploration_alpha)\n",
    "\n",
    "        actor.train_expl(OBS, ACTS, ADS, probs_buffer, exploration_alpha, weights, distance_metric) # update only one step\n",
    "        \n",
    "plt.plot(exploration_loss_log)\n",
    "plt.show()\n",
    "#plt.plot(exploration_alpha_log)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeYVNX5wPHvu31Z6tL70gTp4IpgBUEUsGCLPVgSSzQmJiZBYwQTC2p+do01gWhUjCY2CIqIYANcOrJ0Flh6W9qybDu/P+6d2Tt1Z8vM7My+n+fZZ+89986dc3Gdd+4p7xFjDEoppeqvhGhXQCmlVHRpIFBKqXpOA4FSStVzGgiUUqqe00CglFL1nAYCpZSq5zQQKOVFRP4nIhOiXQ+lIkUDgaozRCRPREZFux7GmDHGmGnhuLaINBaRZ0Rkq4gcFZEN9n6LcLyfUqHQQKDqFRFJiuJ7pwBzgD7ABUBj4HRgPzCkGteL2r2o+KKBQMUEEblQRJaJSIGIfCci/R3HJorIRhE5IiKrReRSx7EbReRbEXlaRA4Ak+2yb0TkryJyUEQ2i8gYx2u+EpGfOV4f7NwuIjLffu8vRORFEXkrwG38FOgEXGqMWW2MKTfG7DHG/MUYM9O+nhGR7o7rTxWRh+3t4SKSLyJ/EJFdwD9EJFdELnScnyQi+0RksL0/1P73KhCR5SIyvCb/HVR80kCg6jz7Q+3vwG1Ac+AV4GMRSbVP2QicBTQBHgLeEpG2jkucBmwCWgGPOMrWAi2AJ4A3REQCVCHYuW8Di+x6TQZuCHIro4BZxpijld91QG2ATKAzcCvwDnCN4/j5wD5jzBIRaQ/MAB62X3Mv8IGItKzB+6s4pIFAxYKfA68YYxYaY8rs9vsTwFAAY8y/jTE77G/Y04H1eDa17DDGPG+MKTXGHLfLthhjXjPGlAHTgLZA6wDv7/dcEekEnAo8aIwpNsZ8A3wc5D6aAzur9S9QoRyYZIw5Yd/L28DFItLAPn6tXQZwPTDTGDPT/reZDeQAY2tYBxVnNBCoWNAZ+K3dvFEgIgVAR6AdgIj81NFsVAD0xfr27rLNzzV3uTaMMYX2ZsMA7x/o3HbAAUdZoPdy2Y8VRGpirzGmyFGfDUAucJEdDC6mIhB0Bq70+nc7sxbqoOKMdjapWLANeMQY84j3ARHpDLwGjAS+N8aUicgywNnME64UuzuBTBFp4AgGHYOc/wXwsIhkGGOOBTinEGjg2G8D5Dv2/d2Lq3koAVhtBwew/t3eNMb8vJL7UPWcPhGouiZZRNIcP0lYH/S3i8hpYskQkXEi0gjIwPpw3AsgIjdhPRGEnTFmC1ZTy2QRSRGRYcBFQV7yJtaH8wci0ktEEkSkuYjcLyKu5pplwLUikigiFwDnhFCVd4HRwB1UPA0AvIX1pHC+fb00u8O5QxVvVcU5DQSqrpkJHHf8TDbG5GD1E7wAHAQ2ADcCGGNWA/8HfA/sBvoB30awvtcBw7CafR4GpmP1X/gwxpzA6jBeA8wGDmN1NLcAFtqn/QormBTY1/6wsgoYY3Zi3f/p9vu7yrcBlwD3YwXKbcDv0P/vlRfRhWmUqj0iMh1YY4yZFO26KBUq/WagVA2IyKki0s1u5rkA6xt4pd/ilapLtLNYqZppA/wHa2hoPnCHMWZpdKukVNVo05BSStVz2jSklFL1XEw0DbVo0cJkZWVFuxpKKRVTFi9evM8YU2lKkZgIBFlZWeTk5ES7GkopFVNEZEso52nTkFJK1XMaCJRSqp7TQKCUUvWcBgKllKrnNBAopVQ9p4FAKaXqOQ0ESilVz2kgUEqpKCguLee9nG2Ul0c/zU9MTChTSql488q8jfzf7HWkJCYwflD7qNZFA4FSSkXQxA9W8OOOwzRtkAzAwcLiKNdIA4FSSkXUuz9s89ivCwmgw9pHICJNReR9EVkjIrkiMkxEMkVktoist383C2cdlFIqWkrKyvm/z9dypKgEwP3bqQ7EgbB3Fj8LzDLG9AIGALnARGCOMaYHMMfeV0qpuDNz5U6e/3IDj89aA8Cv313mc05dWBMmbIFARBoDZwNvABhjio0xBVhL+U2zT5sGjA9XHZRSKpo+X70bgH1HrH6AOWv2+JyzdFsBJWXlEa2Xt3A+EXQF9gL/EJGlIvK6iGQArY0xOwHs363CWAellIqaGSt2AjBv3d6g51z20neRqpJf4QwEScBg4G/GmEHAMarQDCQit4pIjojk7N0b+B9RKaXquuuHdgp6/NiJUn427Qc27zsWoRp5CmcgyAfyjTEL7f33sQLDbhFpC2D/9n1WAowxrxpjso0x2S1bVrrAjlJK1SnOiWLpyYkUFpcGPHfTvmN8kbuHyR//yKxVuyJRPQ9hCwTGmF3ANhHpaReNBFYDHwMT7LIJwEfhqoNSSkVL1/tnurd3Hz5B7wc/q/Q189bt5fa3FpO783A4q+Yj3PMIfgn8S0RSgE3ATVjB5z0RuQXYClwZ5joopVStKCwuJTFBSE1KrNLrpuds8ykb3bu1uzPZ2+HjvsNMwymsw0eNMcvs5p3+xpjxxpiDxpj9xpiRxpge9u8D4ayDUkrVlt4PfsbYZ7+ulWsN6ZIZ8Fj+weO8uWBLxIaW6sxipZSqgo17a6dDd1i35gGP/e795ZQbGNu3Dc0bptbK+wWj2UeVUsrh2IlSsibO4L9L86t9DX8ziJ02PDKGPu2a8OVvzwEgNcnzo9jVz1xUGpn5BRoIlFLKYc+REwA8/Gluja8B0DwjxePY/N+NICnR+ujt2rIhACcCfOAXlZRVuw5VoYFAKaUcNu87CsD+Y9XPCupq23/umkEe1+neqiGdmjcI+TonSvSJQCmlIu7mqTk1vobrG35KoudH7P1je1XpOkWl+kSglFIRd+UpHSo9Z9/RE0GPF9uBIDUpgaFdK0YHndurdZXqsmTLwSqdX10aCJRSymH9nqN+y8scM4UrCwQ//6f1VJGalMDAjs3c21X18Ixcj/cNFw0ESinlsGxbgXt7zLNfk3+wEMAjQ2hpWfAP531HrX6BtJREbj4zi+E9W/L9fSMrfe+59w73KYvECmYaCJRSKoDcnYc58/G5AHy/cb+7/HiIo3naNkmjVaM0pt40hEyv0UMuF/Rp497u0iLD5/jx4vD3E+iEMqWUqsQTs9awaHNFEoRgH84nHB28rRqlVXrtxATx2G+SnswhR4qJUm0aUkqpyPL6XAbgpa82ejTRFAYJBM4Pce8PeX9OzbL6EAZ0aALAB3cM8zjeIKVqeY2qQwOBUko5JCYIlw5q71N+ZvcW7u3b31rMlv2+qSZOlJYx5JE5ADw8vm9I7zfh9Czm/24EH911JgBN0iuakFKSEmjduPKniprSQKCUUrbyckNJmaFpg2SfY9O+3+Kxf86TX/ksMfnkrLXu7Q0BRh95ExGPSWbOp4gXrx0c0jVqSgOBUkrZiu0P9lCbY657baHH/uvfbHZvZ6RWr0nHFQZ6tWnEeb2rNu+gujQQKKWUbcgjXwDw4dIdvHTdYJqk+z4ZOC3KC5xF/7LBlU9M86dZRgpPXN6faTcPqdbrq0NHDSmllO1wkbWc5O8v6MnYfm1pnJbM9W8sDHh+enLgb/01adv/yakdq/3a6tAnAqWU8tK1hZUV9MweLfjozjMCnlda7tlH4Jwr4J1nqC6LnZoqpVQYzVy5073dLKOiSWhAx6bu7btGdOevVw5w75d4zTDu276Jezs5sfKho3WFBgKlVL337Bfr+cW/lrj3GwfoG2iWkcIVXknpnBPISsvK6du+MV//fgQiGgiUUipmPP3FOo/9xmn+A8GanYcBa0SPS5FjzYDSckNGShIdM0Nfc6Au0ECglFIOf7mkT8BjPe0A8Okvz3SXOVcRKys3JMdQ34BL7NVYKaXC5KweLbh+aOeAx4d2tRacT0pMYFy/toBn3qHSchNSWom6RgOBUkrZGqcnB23bd3YGXzTADgQlnn0ESTEYCHQegVJK2Was2MmL1/qWv3vrUPIPHvcoS0+xPj4Li0vdZT/uOFzpWgV1kQYCpVS9VhTC2gKuJiGnhqnWx+fRE2X2bysgrN19pBZrFxnaNKSUimvHi8soCLLK1/ebKhacCbR4jD+N0qxAMOHviwD4et3eatYw+jQQKKXi2skPzmLgn2fz6Yodfo9v2VeRTvrC/m1Dvq7riQDgUGEJ+4+Ff0nJcNFAoJSKW6u2H3Jv3/X2Ur/nTP5ktXv7pjO6hHzthmkVgeBEaRmPzMitRg3rBg0ESqm4dfe7/j/8/fnkrjP9rhkcSCPnE8HxEvfooY6Z6aFXsI7QQKCUils7Co5XfpKtdePUKl1bRHj5emvhmG0HC93lj1/ev0rXqQs0ECil4tZtZ3fz2D9SVBLgTGhVjbTRrlnEN0/NcZftPxp7fQVhDQQikiciK0VkmYjk2GWZIjJbRNbbv5uFsw5KqfqlqKSM6T9sJWviDH7wWjjmnunLavW9/M0irkrzUl0RiSeCEcaYgcaYbHt/IjDHGNMDmGPvK6VUrbjr7SX84YOVAHy3cb/HsdydnmP8XZlDfzoscFqJYMrKfSePOWcfx4poNA1dAkyzt6cB46NQB6VUBO0+XMQ1ry5gxoqdlZ9cQ1/k7gl4bLtXn0HPB2YBVZs/4FRcWl75STEg3IHAAJ+LyGIRudUua22M2Qlg/27l74UicquI5IhIzt69sTtRQykFpz06h+837efOt5ew81DwDty8fcfImjiDdWGaoVta5vvhnZpUvYXmYy3ddCDhDgRnGGMGA2OAO0Xk7FBfaIx51RiTbYzJbtmyZfhqqJSKqMPHS4MeH/7XrwD421cba+09Lxvc3r39zg/byJo4gw17KgJNalL1Pgr7tGtc47rVBWENBMaYHfbvPcB/gSHAbhFpC2D/Dvwcp5SKed7fwIMt+O50MEhaiECM8Z/wbeIFvdzbf/pwFQCjnprvLksLsU7evDOVXjSgXbWuE21hCwQikiEijVzbwGhgFfAxMME+bQLwUbjqoJSKnp2HjrNq+yGKvNrRX54f2jf9dk2rPjHrhNd7dcxM56TWDSsdGlpbq0rGYgpqCO8TQWvgGxFZDiwCZhhjZgFTgPNEZD1wnr2vlIozZz8xlwuf/4YNe456lL+9cGvQ1102yGrGWeA14icUR4o8m52+/v25fH7POQA8eUXgiV7++g2qI9iiNnVZ2NJQG2M2AQP8lO8HRobrfZVSdUOJnZd//IvfVul1TRpY6wVvciSDcyoqKWPJloOc3r2Fz7FFmyvmDfxiuOdksmDj+0tqYQ2BAR2acErn2JwWpTOLlVIRMbRrpns7UFs+VOTwufrUjn6P9/rTLK59fSFrd3mOKhrz7Nfc+fYS9753X0SP1o0IpFmG/8XqQ/HxXWcA8Mdxvat9jWjTQKBUnHpq9jqyJs5g+g/Bm2Jq6q63l/CfJfkAfLdxn09TkMspnZu51/ndsr/QvZCLt1J7ktanfuYcbHY8JRw67pkuInfnYY/9s0/yHG3YJD2ZvCnjfPoDXrx2MJcMaE919e/QlLwp4xjSJbPyk+soDQRKxann5qwH4A8frAz4oVtTx06U8umKnTwyIxdjDNe+tpBRT81jydaDPueempVJdpbVdDL8r18FbDJyzdY9eqKUcq+Zu3e8tdi9HayDd/NjYxnQsWmAY+Pc2ye3bcy4/m1JiNFO3tqigUCpOHTM64O/76TPKKmlDlGn9xdbTwL7jxWz0pH7/+nZ63zOHd6zlcc3+kBPDs72+je+2ezeNsawxtEcFGxWb7AF6AHypozj5esH89YtQ4KeV19oIFAqDnmPnoHQ1uat2nuUMOnjH937F79Q8Q1/RE+/CQNYkX/Ib/mybQW8uWALAGXlFR/whx3ZQl3HXa57fSEzV1Y/ZcUFfdvSvGHVUk/HK128Xqk4tCK/wKfseEkZjdKq3ynqbeGmAwGPHQ8QdP5wQS+ueW2Be7+s3JCYIO5monlr9/JF7m738ee/3MC5vVpxvKSMdxdt87ne1G/zaNYghWHdfBeXV6HTJwKl4tCtby72KSsqrt2mob9/uzngscN2R+49o07yKG+U5vnd05X908UZBFwufek7rn1tIau9OoMBFuUd4JrXFrBlv/+hpio0GgiUqif+szS/Vq93xSkdAh57Zf4mAO4c0Y3vJp7LvN8NB3xTORSV1E5wCrQesQqNBgKl6olnvlhfq6OH/OXi95aYILRrmk7n5tZkrgYp3oEgcL9Frzb+x/23auTbru/sqL7x9KxK66U8aSBQKs54j6d3ygswW7c6vPP6gO8HvffoHe9JXmOf+9pniChYs4BdQ029/c1eJ9ifW87swqSLYndiV7RoIFAqzjjXzN382FiPYwmOD+aV+Yc8RuVUxarth3jAzuL57q1D3eWPXNo36Ou8m4YKCkuYt853vZHe7RrTJN1/x/YpnQNP3PrVqB6VDh1VvjQQKBXDSsvKmbVql0fKhgapFR+2IuKRY8f1Gbm94DgXvfAN/Sd/XqX3M8bw8ryNPDoz113m7ABunlHRbOOvaSc50fdD+oif5qq0pEQapFRtUOMfx55M41ocFVWfaCBQKoa9MHcDt7+12CMdQ0qi9b/1y9efAsDce4dz5wgrAZtrUtkRx5PA7NW+I3UC+X7jfqb8b43HWsDOD1/nE4e/PgR/i70//r81PmVXndrRp5nJacF9I3n26oEeZX3ax8ciMdGggUCpGLbSnqD1y3eWutvaXbl6nKtundbFGmfvbzbuy/NCWx/gwLFi/vzpap/ydMcHdmFxxbf7X4zo5nOuiPCvn53GD38c5S7zXkd4xt1nMqRLZtBA0KZJGpcM9MwPNKyrziWoLg0ESsWwbq0aurc/XLYdqJiZ6/z2nWw/JTz35QbKy41HQFi8xTcvkD+D/zLbI8WDS3PHwu+nZlnt949d1o9LB/kfXnpG9xa0dIz8ae+1AE2fdk0AWB5gFrI/F/Rpo30DNaCBQKkYlX+wkFft8foAv3lvOVkTZ7BxjzUyyLlaVor9dDB/3V5e/XpTrY3fB8+RQc0yUsibMo5rhnQK+fVHAnRYNw3QWew0YZi1EEyLRimVnKmC0UCgVB1xwxsLyZo4w2e2bSBnPj7Xb/nvP1gBeD4ROJuJpvxvDc9/ud7jNc4mHX/8DfF0uvH0LO4e2SPoOd6+unc4AIf95EUCOK93a8BKH+3a9jbEbvI6KchaA6pymmtIqSj5buM+erVpTGZGCjsKjvP1+n2AlTAutWH1FlN32ucYRpqS5Pmdr1kDz2/Qx4vLgo7S2Xf0hMd+91YN6dm6kbuDdvLFfapcvyyvFcOGdMlkkCN19KBOzcibYqWMvuGNhX6vMbZfG/558xDO6uG7WpkKnQYCpSJsTu5uth4o5KFPrI7XvCnjPL6RF54og4aBXm0JloLZZXtBoXvbNZLI5ePlOzz2vReY9zbm2a/d2xkpiXzxm3Mqff+qeu+2YQGPPTCuN+c/M5+7RnT3KBcRnwVoVNVp05BSEXbLtBx3EHBx5uA/VkkzDcDWAxUf8s9dM8jvOUMdo2i8nwhcRvS0PkR/6Vji0Z/9x4qDHg+3nm0asXzSaH47+qTKT1ZVpoFAqSgrLSunsLiiX8B7URl/Fm+pSAF9ob38o7fOmRVNL4ECwXWnWZ2tS7b6pq0O5Fhx7a5rEKom6ck6MihMNBAoFUGlflYJ6/7H/3ms3BXKB+0fPlgJwNSbTg24zKKh4ikjUCBIDzJWP5K8m3xUZGkgUCqC5q/3zasDcO+/l7u3F27a7/ccF2d+oKYN/A+bbJia5HHMu48AYEDHpqQlV5S/uWALwx6bU2lW0f4dmgQ9XhVL/nQe943ppU0+UaaBQKkIMcZw89ScSs8LtLqXS4mjY9c1LHTRH0cy1x6OCbBy8miP1/gLBFNvPNUjJcSfPlzFzkNFbNrruZZwKOmmqyszI4XbzummTT5RpoFAqQgpDfED1ZVa4f3F+cxa5bsm746CIve2KxC0apRGlxYZzPr1Wfzz5iE+H6wJCcL4ge2YdnPFYu3pKYkMdAzXDFRP1wilM7tbQzR3HSryeY2KbRoIlIqQEj/9A/68OHcjc3J3c++/l3P7W76jeTyGhXq1/fdq0zjgcMpnrh7EOY5jacmJiAj3j+3lcZ73E4lr8RhX5tA9RzznFKjYp4FAqQgJZey/yy3TAjch7bS/kT8w7mQ6NGtQ43pdP7Szx75z1bD/Ls0n/6CVFG5c/3YMycrk83vOrvF7qrpFJ5QpFSHFfp4IFt0/kiGPzgn6OmOMR1OPaw7CpYPaB3pJUPeOPskjrUOCVzOSq+lnw56j3DN9uXtpyCbpybx3e+BJXyp2aSBQKkKcTwQ3np5Fw9QkWjVO8zina8sMNu31XE7yvZxtXHWqbxK3jNTq/e9717meOYG8Vw17dGYuFw9ox/WvW2kdXE1BjdP04yJeadOQUhHinLR1Vo8W3Ht+TwBWPXS+u/yJy/v7vm6L9br8g4UeOX9SA8wNqA5nP8FPsjuy81ARuw57dgo3aaCrf8WrsId4EUkEcoDtxpgLRaQL8C6QCSwBbjDGRHf+ulIRcPc7SwE456SWnNurlbu8YWoSky/qTXZWJn3b+47Rn56zjek529z7KYkJnNmjRa0OubxhaBY7CoqY+l0eL3210e/C8YHWEFaxLxJPBL8Cch37jwNPG2N6AAeBWyJQB6XqjOE9W/p8iN94RhefIODKte+tuKyc7zbuq9U6packMumi3u79VdsP+5yjgSB+BX0iEJGVQMDBz8YY3+dYz9d3AMYBjwC/Eeuv/1zgWvuUacBk4G+hV1mp2LPb0cziWsUrkCcu70+P1g0Z1KkZ077f4vec2lxYxsUZnJ6avc7neHpy3UhHoWpfZU1DF9q/77R/v2n/vg4o9D3dxzPA7wHXqhHNgQJjjGvIQj5QvaEPSsWQeesqUkv4a/5x+smpHcNdnSp7+qoBOvs3jgUNBMaYLQAicoYx5gzHoYki8i3w50CvFZELgT3GmMUiMtxV7O9tArz+VuBWgE6dQl/2Tqm6qKE9wueUzr5t79WRFCDRXE2dfVJL5juC1sy7z6J3u8ZheS9Vd4TaR5AhIme6dkTkdCAjyPkAZwAXi0geVufwuVhPCE1FxBWAOgA7/L3YGPOqMSbbGJPdsqUuPKFimyu52x/HnVyl10V6yOZrPz3FY1+DQP0QaiC4GXhRRPJEZDPwkl0WkDHmPmNMB2NMFnA18KUx5jpgLnCFfdoE4KNq1VypMCksLmXP4drNp+Nab6BhFcf+T7GHk57RvXklZ9aO1KREvwnqVHyr9K9SRBKA7saYASLSGBBjzKEavOcfgHdF5GFgKfBGDa6lVK27/G/fk7vzsHu93NrgCgRV7XAd268tyyeNJnfnYb7dUJGe+uHxfWutbt4yUhMpLqz9zmhVd1Ua+o0x5cBd9vbh6gQBY8xXxpgL7e1NxpghxpjuxpgrjTGawUrVKbk7fYdO1tRxOxA0qMZCME3SkxnatblHYLp6SPj6zQ4WllR+kooroT6nzhaRe4HpgHv+uzHmQOCXKBXbvHP81IQro2dNVwT7+43Z5O0LZcBezQ3vqX1z9UWogcDVH3Cno8wAXWu3OkrVHYXFZdXO5+PvWgBpSTULBOf2al0b1QmJTiCrP0LqFTLGdPHzo0FAxbWC47XXRPLcnPUAAdcXrktuPdv6X3vl9pp0BapYEvLXHRHpC/QG3OkSjTH/DEellIq0opIypv+wjQ7N0t1lB48V075pepBXhWbDnqOVn1SH9LGHjG7ZH5kmKBV9IQUCEZkEDMcKBDOBMcA3gAYCFRdOn/IlB4555j4s8NNpunbXEf6ds42M1CTuOS+0BddHPTWvVuoYKZcMbM++o8X8JLtDtKuiIiTUJ4IrgAHAUmPMTSLSGng9fNVSKrJco3qcCo77JsU9/5n57u1fjOhGag3b/OuqW87sEu0qqAgKdebIcXsYaak9l2AP2lGs4ki/Dr75f7yHUS7ectBjv6QstMXoXTpm1ryZSalwCDUQ5IhIU+A1YDHWOgKLwlYrpSJs0WbfkdCzVu302Hct4ejSd9JnZE2c4bHGbzD/vu306ldQqTAKqWnIGPMLe/NlEZkFNDbGrAhftZSKPudMXoCcLf6nzSzcfIBzTgo+5v7KUzrQpkla0HOUipaQnghE5J8i8nMR6WWMydMgoOLB7sNFFBaX8vbCre6y924bxgd3VHxzf3dRxbHVO/zPOA6WNuLYCSvjeufmDWpaXaXCJtSmoalAW+B5EdkoIh+IyK/CVy2lwssYw2mPzuHC57/h/v+uBGBkr1YM6ZLJKZ2buVNB/G3eRgDeXLCFJVutPgLvPD+l5YHz8lz4/Df2OVXrT1AqkkKdUPYl1ipjf8IaLZQN3BHGeikVEmMM7y/O54lZa8iaOIPvNu7DmMo/dD9ZYbX/b9rrzpjCsG4VGT6/+M05AIzs1ZqV+Yf404erKCkzDO2aSbnX9a99bWHA99m8z7p+m8baLKTqrlCbhuYA3wJXAWuBU40xvcJZMaVC8eWaPdz77+W89JX1zf3a1xby6YqdlbwK/v7NZp+yxo6UCu2appOSlMDWA4XM+rHieo3SkhnXr23ITT2uvoNLB+tCfKruCrVpaAVQDPQF+gN9RUTHwqmoW+9n1u5fP1/r99yHPvmRrIkz2Hag0G9zTnFpuc/+F7m7eX9xvrts9urdNG+Yylf3Dvc4d+2uI5R5Nf9c/er3zFu3l+6tGsbtfAMVH0JtGrrHGHM2cCmwH/gHUBDOiikVCn8dtVv2F3K4yHdW8D++zQNg2bYCVm337fgNNAx092HfTOkiQt6UcZzfx0oCd/4z87ln+jLAaq6a+u1mFmyyRhnFWooJVf+E2jR0l4hMB5YB44G/Y6WZUCqqmmWk+C3vP/lzCotL/R775TtL/ZaHMh/grhHdPfZbNkp1b3+83Fp1de7aPUz+ZHWl11Kqrgi1aSgdeAroZYwZaYx5yO5AViqq1u064t5e+/AFtGhYERiWba14aN1RcDzodZIShIsGtPMoG9ypqc955/X2TAPdomGqx/7x4jJC6KtWqk4JtWnoSSAZuAFARFqKiCYjUVH3wtwNACyfNJrUpESxWZxLAAAaFklEQVT2Ha3ID5SWkkjevmM8+dkaTp8S/HvL2ofH0Ll5hkfZiJ6tfM5L9lrPNyXJc/+qV7/36SuY/7sRld+IUlEUatPQJKy1hu+zi5KBt8JVKRX/Bv9lNlkTZ9ToGs4P3EZ+FpA5dqKUO/61hBfnbvT7+um3DnVvJ/pZJ+BmO/Fao7SKaycnep7n7EgGWJF/iFvfXOxR1kknk6k6LtSmoUuBi7GXqTTG7AAahatSKv65Uj6fKA0tT48/3e6f6d72t+DLkaLSoOsPt20SfOBbRmoSeVPGsXLy+UwcY42WbuU1H+DqUztWpcpK1UmhBoJiY83SMQAiklHJ+Ur5deBYMSVlFcM0H5mRG/DcmSt3ct9/Vlb7vVyrgvnz61E96JiZzl/G9+UfN55a6bVuO7sr6x8Z47N844TTswC4/Zxu1a6nUtEW6noE74nIK0BTEfk51hrGuh6BqpJdh4oY+tgcj3TM7yzayp8v6ev3/F/8awkAj13WL+h1n7i8v3t782Nj2X+smOyHv2CNoyPZ5YFxJ9OiYSrjB1kTvG4Y2jmkuouIT7MQQGpSInlTxgHw8jzPJqjkRNEAoWJCqNlH/yoi5wGHgZ7Ag8aY2WGtmYo7ruyd2w5UjOApKTMcOl4SdKH0XYeK3Jk7DxWWkJqcQFpyIimJCSQkwBWnVKykJSI0Tgt8rZ+dFb5lNL74zdmMeqpi4Zr1j4wN23spVZtCbRrCGDPbGPM7Y8y9wJcicl0Y66XiUGYD/2P+Bzz0OZ+u2BHwdUMfm0Op3Zw0/K9zueSFbwFIShSuP62zT/+A90geV96gcOveqhGndckEcD8lKBULggYCEWksIveJyAsiMlosdwGbgJ9EpooqVhljePjT1fy44xAAR0/4n+AF8O2Gfe7t/y7N5w/ve2Y6f+5La5jowcIS1u4+wo6C4xQWl3GkyP81xREburTI4LQumfzrZ6dV91ZC9sK1g5lx95lhfx+lalNlTUNvAgeB74GfAb8DUoBLjDHLwlw3FeO63GeN6vlkxQ4W3j+KYwFm+gL0aVexVOQ905f7HN+096g7tz/gnhcwPWcbj1/R3+f85MQEd+6gxARh+m3DqncTVdSyUarHbGOlYkFlgaCrMaYfgIi8DuwDOhljfHvhlHJwjgwqKCwh/2Ch3w94l8pSR89evZuJY3wXk//LJX38nu9qLfrLeP8d0UqpCpX1EbgzdxljyoDNGgRUKA4dr0j6dqK0nA8Wbw96/gn727v3BC1XSocTpeUcO+E75+C83m38Xq+oxLreD37WIlZKeaosEAwQkcP2zxGgv2tbRALP1FH1nvfiLfPW7fHY79m6EdcP7eTe32gvEHPvvz2fGl77aTYicFV2R79J5Cprhrl7ZI8q1Vup+iho05AxRpOoq2rxzrezxE4Al/PAKFKSEkhJtIaAvrXAWhP4nUVbA84XMMbqC7hkYDufY/5SQzh1a6lzH5WqTKgTypQKyYr8Av6zZDu32Hl62jZJY+ehIsDKB+SdrfP8Pq357MfdAOw5XORx7OS2jT32b5r6g8f+364bHLAeyyeNpqzcIBI8UCilwhgIRCQNmA+k2u/zvjFmkp219F0gE1gC3GCM8e0FVDHpYnuM/9Tv8gDo176JOxCM69/W5/xXbsh2J58b8ugcd/kvz+3uDiYurn6Er+4dzg95BxjTz/d6LsEmqCmlPIU8oawaTgDnGmMGAAOBC0RkKPA48LQxpgfW0NRbwlgHFWWfr97t3k5P8d/S+NDFniN/hnVtzm9H96RpgAloWS0yuDJbk70pVVvCFgiMxbVGX7L9Y4Bzgfft8mlYK56pOmTDniM+E7qq60pH+ocGAQJBhlcK6csdrwF49uqBtVIXpZR/4XwiQEQSRWQZsAeYDWwECowxruEf+UD7AK+9VURyRCRn79694aym8jLqqflMz9nGlv3Hanyt6xxJ3fYf9d8CePCYZ/naXZ4D0i4Z6PdPRClVS8IaCIwxZcaYgUAHYAhwsr/TArz2VWNMtjEmu2XLluGsprIt3LSfcsdon71HfBdtr4rNj42lf/uKGcNf5O7xe97NXn0B/pqE1vzlAs7q0UJX+1IqDMIaCFyMMQXAV8BQrFTWrraADkDgbGMqYnLyDnDVqwv486cVi64HCwTFpeUcKSrxKHPOJr6wf1tExCMhXGqS/z+3xATh019W5Oe5bLDvE0BaciJv3nKarvalVBiELRDY6xo3tbfTgVFALjAXuMI+bQLwUbjqoELn+tB3jfYBOOz1Qe+y+3ARJz3wP/pN/tyj/KidAO7BC3vzwrUVQzubNrBG8Nw5onvA9+/reHIIlkZaKVX7wvlE0BaYKyIrgB+A2caYT7HWPv6NiGwAmgNvhLEOqgYOH/efJO40xzDPBZv2u7e3F1jrDDjX+AWYdtMQRp3ciiuzPTuBAwnUqayUCo+wzSMwxqwABvkp34TVX6DqEH/zrh6ZmcvPzuoSdFKWM5PE1gOFgG8b/4COTXl9QuXLQb532zCWbj2ok8CUirCI9BGouu/ZORv8ln+5xn8Hr4uzn8CVJrpXm0bVqsOQLpncpks7KhVxGgjqmROlZSzfVuBTnrvTfw7Bg4UVH/TfbdzHeU/NA2Bkr1YAbN5XMcT0eImVHTTQxDGlVN2kgaCe+WDxdi558VuPtn3nWgDzfjec//zidPf+zJU73dt/+GAF6/dYcwTz7DkGT3y21n38q7XWfA9t41cqtmggqGcenZkLwCJHnv68/Vbb/rWndaJz8wwGd2rGzLvPAjybhpwTwm4722rCKSs37LaTxbnOTUvSQKBULNFAEIdunvoDT89e597fsOeIe71g1++nHMen/7ANgE6ZFWP0e7eryPxZZDf5FBZXLAxzTs+KSX5//3azx/t7LyavlKrbNBDEoS/X7OHZOespLi3HGMOop+bTd9Jn7iyfLrvsrKCd7UlaFw/wzfcPuL/xd2lRkdu/deM09/Yr8zYBkJQgDOjQBKVUbNFAEMdOeuB/FDtm+3ob+tgcXp63kfv+sxLwTf520xlZAGyyVw9LS7aafFwdxZcPrpgXsL3gOKXlhuX5h2qt/kqpyNBAEIP2HC7yWex96/5CjDE+K4O51u51Or+PtQ5wZkYKU/63xl3eyCsQXH2qtZTkTVN/oKSsnNydh8lq3oAX7QVh/u8nA+jZ2hoqesaUL2t4V0qpaNFAEGPW7jrCkEfn8NbCre6y17/exNlPzuXV+Zt445tNHue72vf9OeCV9dO7bd85+ufr9daIoLz9he4nA4C1u494vGZgx6Yh3olSqq7QQBBDDheV8NmPuwCY/PGPdL9/JjsKjvPwDGsk0JzcPTw6c43Ha5zpIAAyUhLdwzwr4wwEN0/NAeDRS/2vK+zyq1G6WLxSsUbXLI4BHy/fwUmtG3LBM1+7y1xNQI/YQQBgUd4Bn9e63DPqJJo3TGFIl0w27T3G7W8t9jj+xOX9fV7j3WcA0K5pmsf+32/MdgcJgKzmuli8UrFGnwjquFXbD3H3O0s9goBToBnBo05u7bF/bq9WXD+0Mye1bsQFfdv4nD+mn29ZWnIiU2/yzBHkvfj8ub1aM+vX1pyDk9s29hhZpJSKDfpEUEe58vYkVjImf9M+/6uIPX55PyZ9nMCnK6yZwf28hnWe3q05B44Vc7ykjMcu60ejAKmfh/ds5bHvnVkUoFebxmx+bGzQeiql6i4NBGH2k1e+Z0hWJvee37NKrzvt0TkcPVHKhGGdKz8ZGNGzJXPttv9/3HgqzRum8sil/dyBwNs/bx5CYoJUOdNnk3T/AUMzhioVuzQQ1DJjDN9s2Ed250xSkhJYtPkAizYf4NZzulZpwRXXDOBp328J6fx/3DSED5du57SumbRtkg5YH9rv/Hyoe0KYU1Ji6K2CeVPGcaK0jPyDx/0uI6mUim0aCGrZmwu28OBHP/qU95/8OXlTxoV0jSdmrQl6fPJFvRndpw1Pz17Hvxfnk2GP7hk/yHeJx2Hdmof0npVJTUqkW8uGtXItpVTdop3FtcxfEKjMsROl5B+0Er8dKSrhpa82+j3vzhHdyO7cjBvP6EK7puk8fGlfALq10g9opVT16RNBLWvbJI2dh3ybYoJNtLrmtQWsyD9E3pRxzFq1y+f4+IHt2Lj3GHeP7EHq+RVj+1OTEvnnzUM81vtVSqmq0kBQQ0eKSrj+9YU8elk/mjVI8RsEsjs3IyXJ9+Hr6IlS+k76zL3vnRTO5dyTW/PM1f4Twp19Uku/5UopFSptGqqhj5btYHn+IcY99w2ne+XbObltYz6443Rythzku437fV77ZJC+gAcv7O3e1qzOSqlw0ieCGnrgw1V+y0PpGN7vlevH6aYzsvjzp6uBijkFSikVDvpEUAO3vZnjt/ysHi089m88Pcsns2dJWXnAMf5/urA3IsIIe/EXf81KSilVW/QTpgY++3G3T9n1Qzvx6g3ZHmWN05M5WlxKuSNF9Hs529zbz10zyOP8nQXHAXj8iv5ceUoHxvRtW5vVVkopD9o0VE3e6wEEawpqkp6MMXCkqJQmDaxJZfkHrQ/7287pysUD2nHxgHZc9/oCvt2wn0I7dXSrRmk8eeWAMN2BUkpZ9Imgmvwt+BJIYzs/j+spYN3uI/zNnitwz6iT3Oe5hoG2yNDZu0qpyNEngmpataNiScbHLgueo9+VluGRmblkZzXj0pe+cx9zLvLy65En0TQ9hZ+f1aWWa6uUUoFpIKiG8nLDlS9/D1gdwdcM6RT0/HMcY/2dQcBbekoidwzvVjuVVEqpEGnTUDW8PL8iBUTvto0rPT/QqJ+0ZP3nV0pFn34SVcMTs9a6t6/M7hDSa8YP9J0ZvPRPo2utTkopVV0aCGpg+aTRIefhn3B6lsd+3pRxpDvWBFZKqWgJWyAQkY4iMldEckXkRxH5lV2eKSKzRWS9/btZuOoQDidKy9zbgRZp8UczhCql6qpwPhGUAr81xpwMDAXuFJHewERgjjGmBzDH3o8ZOwp8k8qFonFaMq/ecAoAnTIb1GaVlFKqRsI2asgYsxPYaW8fEZFcoD1wCTDcPm0a8BXwh3DVo7YVFFr5gf5ajYleo/u0YfmDo8lI1SYhpVTdEZE+AhHJAgYBC4HWdpBwBYtWAV5zq4jkiEjO3r17I1HNShlj3MM/u7bMqNY1mjRIrtIykUopFW5h/0QSkYbAB8CvjTGHQ32dMeZVY0y2MSa7Zcu6kXP/6/X73NvNdfavUipOhDUQiEgyVhD4lzHmP3bxbhFpax9vC+wJZx1q05GiinTQ2s6vlIoX4Rw1JMAbQK4x5inHoY+BCfb2BOCjcNWhtjWw2/YfHt835GGjSilV14UzxcQZwA3AShFZZpfdD0wB3hORW4CtwJVhrEOtevHLDQCM7adpoZVS8SOco4a+AQJ9bR4ZrvcNl+PFZeRsOQhApvYPKKXiiA5fCdF3G/dVfpJSSsUgDQQhumWatSzlb887qZIzlVIqtmggqKKWjVKjXQWllKpVGgiqqH2z9GhXQSmlapUGghCsyC8AoEXDFM7qUTcmtymlVG3RQBCCi1/4FoB9R4ujXBOllKp9GggCKC0r58W5Gzh4rOLD35U9VCml4omuWRzA4i0HefKztTz5mbUaWd/2jRndp02Ua6WUUrVPnwgCuOrVBR77vz+/V5RqopRS4aWBwA9jjE9ZddNOK6VUXadNQ37c9uZi9/bFA9rRq20jOjTTbKNKqfikgcCPPUdOAPD6T7MZ1bt1lGujlFLhpYHAYf/RE5zy8BfufQ0CSqn6QPsIHE595IvKT1JKqTijgcCh3NFH/Pw1g6JXEaWUiiBtGrKtzD8EwMCOTXl4fF/6tm8S5RoppVRk6BOBbfxLVhqJP1/SR4OAUqpe0UAAbNhzlDK7Xah/h6ZRro1SSkVWvQ8E+46eYNRT8wD49ageUa6NUkpFXr0OBPuPniDbMVy0tMx3RrFSSsW7eh0InHMGANo2TYtSTZRSKnrq7aihQ4Ul7u0vfnM2xaWGk9s2imKNlFIqOupdIDDG8NAnq5n6XR5gzRfo3koDgFKq/qpXgaC0rJyHPlnNmwu2uMv6tGscxRoppVT01ZtA8NGy7fzq3WXu/ccu68dV2R1JSJAo1koppaKvXgSCT5bv8AgCANcM6RSl2iilVN0S14Fg6daDPPjRj6zcbqWPaNYgmUsGtueWM7tEuWZKKVV3xHUguPSl79zb4/q15cXrBkexNkopVTfF9TyCu8/tDsD1QzvxwrWaTVQppfwRf+vz1jXZ2dkmJycn2tVQSqmYIiKLjTHZlZ0X108ESimlKhe2QCAifxeRPSKyylGWKSKzRWS9/btZuN5fKaVUaML5RDAVuMCrbCIwxxjTA5hj7yullIqisAUCY8x84IBX8SXANHt7GjA+XO+vlFIqNJHuI2htjNkJYP9uFehEEblVRHJEJGfv3r0Rq6BSStU3dbaz2BjzqjEm2xiT3bJly2hXRyml4lakA8FuEWkLYP/eE+H3V0op5SXSgeBjYIK9PQH4KMLvr5RSykvYJpSJyDvAcKAFsBuYBHwIvAd0ArYCVxpjvDuU/V1rL7ClsvMCaAHsq+Zr66J4up94uheIr/uJp3uB+ns/nY0xlbatx8TM4poQkZxQZtbFini6n3i6F4iv+4mnewG9n8rU2c5ipZRSkaGBQCml6rn6EAhejXYFalk83U883QvE1/3E072A3k9Qcd9HoJRSKrj68ESglFIqCA0ESilVz8V1IBCRC0RkrYhsEJE6mem0Kum6xfKcfT8rRGSw4zUT7PPXi8gEf+8VgXvpKCJzRSRXRH4UkV/F+P2kicgiEVlu389DdnkXEVlo1226iKTY5an2/gb7eJbjWvfZ5WtF5Pxo3I9dj0QRWSoin9r7sXwveSKyUkSWiUiOXRaTf2t2PZqKyPsissb+f2hYxO7HGBOXP0AisBHoCqQAy4He0a6Xn3qeDQwGVjnKngAm2tsTgcft7bHA/wABhgIL7fJMYJP9u5m93SwK99IWGGxvNwLWAb1j+H4EaGhvJwML7Xq+B1xtl78M3GFv/wJ42d6+Gphub/e2//5SgS7232VilP7efgO8DXxq78fyveQBLbzKYvJvza7LNOBn9nYK0DRS9xPxm43gP+ow4DPH/n3AfdGuV4C6ZuEZCNYCbe3ttsBae/sV4Brv84BrgFcc5R7nRfG+PgLOi4f7ARoAS4DTsGZ0Jnn/nQGfAcPs7ST7PPH+23OeF+F76IC1Dsi5wKd23WLyXuz3zsM3EMTk3xrQGNiMPYAn0vcTz01D7YFtjv18uywWBErXHeie6ty92k0Jg7C+Rcfs/dhNKcuwEiTOxvoGXGCMKfVTN3e97eOHgObUnft5Bvg9UG7vNyd27wXAAJ+LyGIRudUui9W/ta7AXuAfdtPd6yKSQYTuJ54Dgfgpi/WxsoHuqU7dq4g0BD4Afm2MORzsVD9ldep+jDFlxpiBWN+mhwAn+zvN/l1n70dELgT2GGMWO4v9nFrn78XhDGPMYGAMcKeInB3k3Lp+P0lYTcR/M8YMAo4RfAXHWr2feA4E+UBHx34HYEeU6lJVgdJ1B7qnOnOvIpKMFQT+ZYz5j10cs/fjYowpAL7Cao9tKiJJ9iFn3dz1to83wVqlry7czxnAxSKSB7yL1Tz0DLF5LwAYY3bYv/cA/8UK1LH6t5YP5BtjFtr772MFhojcTzwHgh+AHvaoiBSsDq+Po1ynUAVK1/0x8FN7xMBQ4JD9uPgZMFpEmtmjCkbbZRElIgK8AeQaY55yHIrV+2kpIk3t7XRgFJALzAWusE/zvh/XfV4BfGmshtqPgavtkThdgB7AosjchcUYc58xpoMxJgvr/4UvjTHXEYP3AiAiGSLSyLWN9Teyihj9WzPG7AK2iUhPu2gksJpI3U80Onki2AEzFmvkykbgj9GuT4A6vgPsBEqwovktWG2xc4D19u9M+1wBXrTvZyWQ7bjOzcAG++emKN3LmViPoSuAZfbP2Bi+n/7AUvt+VgEP2uVdsT78NgD/BlLt8jR7f4N9vKvjWn+073MtMCbKf3PDqRg1FJP3Ytd7uf3zo+v/71j9W7PrMRDIsf/ePsQa9ROR+9EUE0opVc/Fc9OQUkqpEGggUEqpek4DgVJK1XMaCJRSqp7TQKCUUvWcBgJVb4hImZ2p0vUTNCOtiNwuIj+thffNE5EWNb2OUuGiw0dVvSEiR40xDaPwvnlY47z3Rfq9lQqFPhGoes/+xv64WGsPLBKR7nb5ZBG5196+W0RW27nf37XLMkXkQ7tsgYj0t8ubi8jndvKwV3DkfxGR6+33WCYir9hJ7RJFZKqIrBIrv/49UfhnUPWYBgJVn6R7NQ1d5Th22BgzBHgBKwePt4nAIGNMf+B2u+whYKlddj/wT7t8EvCNsZKHfQx0AhCRk4GrsJKlDQTKgOuwZpS2N8b0Ncb0A/5Ri/esVKWSKj9Fqbhx3P4A9ucdx++n/RxfAfxLRD7Emv4PVkqNywGMMV/aTwJNsBYbuswunyEiB+3zRwKnAD9YaZlIx0oi9gnQVUSeB2YAn1f/FpWqOn0iUMpiAmy7jMPK7XIKsNjOyBks5a+/awgwzRgz0P7paYyZbIw5CAzAym56J/B6Ne9BqWrRQKCU5SrH7++dB0QkAehojJmLtbBLU6AhMB+raQcRGQ7sM9b6C87yMVjJw8BKGnaFiLSyj2WKSGd7RFGCMeYD4E9Y6YeVihhtGlL1Sbq92pjLLGOMawhpqogsxPpydI3X6xKBt+xmHwGeNsYUiMhkrBWlVgCFVKQLfgh4R0SWAPOArQDGmNUi8gDWqloJWBln7wSO29dxfTG7r/ZuWanK6fBRVe/p8E5V32nTkFJK1XP6RKCUUvWcPhEopVQ9p4FAKaXqOQ0ESilVz2kgUEqpek4DgVJK1XP/D4z9yOqdVDspAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code Evaluation: DO NOT CHANGE CODE HERE\n",
    "from numpy import convolve, ones\n",
    "def movingaverage(interval, window_size):\n",
    "    window= np.ones(int(window_size))/float(window_size)\n",
    "    return np.convolve(interval, window, 'valid')\n",
    "from pylab import plot\n",
    "%matplotlib inline \n",
    "\n",
    "rm=movingaverage(rList, 100)\n",
    "plot(rm)\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval performance of PG agent: 59.8725\n"
     ]
    }
   ],
   "source": [
    "# Code Evaluation: DO NOT CHANGE CODE HERE\n",
    "# after training, we will evaluate the performance of the agent\n",
    "# on a target environment\n",
    "eval_episodes = 400\n",
    "record = []\n",
    "env = gym.make('CartPole-v0')\n",
    "eval_mode = True\n",
    "for ite in range(eval_episodes):\n",
    "    \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rsum = 0\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        # epsilon greedy for exploration\n",
    "        if eval_mode:\n",
    "            p = actor.compute_prob(np.expand_dims(obs,0)).ravel()\n",
    "            action = np.random.choice(np.arange(2), size=1, p=p)[0]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        newobs, r, done, _ = env.step(action)\n",
    "        rsum += r\n",
    "        obs = newobs\n",
    "    \n",
    "    record.append(rsum)\n",
    "\n",
    "print(\"eval performance of PG agent: {}\".format(np.mean(record)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
